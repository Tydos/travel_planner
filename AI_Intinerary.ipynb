{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66dcf5e3",
      "metadata": {
        "id": "66dcf5e3"
      },
      "source": [
        "## -"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620664a8",
      "metadata": {
        "id": "620664a8"
      },
      "source": [
        "### Setup and Sample inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "89d59419",
      "metadata": {
        "id": "89d59419"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "cb2924a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: requests in /Users/manoja/Library/Python/3.9/lib/python/site-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from requests) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from requests) (2023.7.22)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "d0e9fbf2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.2.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a78dab0",
      "metadata": {
        "id": "6a78dab0"
      },
      "outputs": [],
      "source": [
        "# 5 fake travelers with different tastes & budgets\n",
        "group_members = [\n",
        "    {\n",
        "        \"id\": \"u1\",\n",
        "        \"name\": \"Alice\",\n",
        "        \"origin_city\": \"Chicago\",\n",
        "        \"total_budget\": 5000,  # USD for whole 2-day trip\n",
        "        \"preference_weights\": {  # 0–5 sliders from your UI\n",
        "            \"nightlife\": 4,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 1,\n",
        "            \"food\": 5,\n",
        "            \"urban\": 1,\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u2\",\n",
        "        \"name\": \"Ben\",\n",
        "        \"origin_city\": \"Boston\",\n",
        "        \"total_budget\": 10000,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 2,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 1,\n",
        "            \"food\": 3,\n",
        "            \"urban\": 1,\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u3\",\n",
        "        \"name\": \"Carla\",\n",
        "        \"origin_city\": \"Atlanta\",\n",
        "        \"total_budget\": 650,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 1,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 4,\n",
        "            \"food\": 3,\n",
        "            \"urban\": 1,\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u4\",\n",
        "        \"name\": \"Deepak\",\n",
        "        \"origin_city\": \"Dallas\",\n",
        "        \"total_budget\": 5000,   # more budget-constrained\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 1,\n",
        "            \"adventure\": 3,\n",
        "            \"shopping\": 2,\n",
        "            \"food\": 3,\n",
        "            \"urban\": 4,\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u5\",\n",
        "        \"name\": \"Emma\",\n",
        "        \"origin_city\": \"Seattle\",\n",
        "        \"total_budget\": 3100,  # willing to splurge\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 5,\n",
        "            \"adventure\": 2,\n",
        "            \"shopping\": 1,\n",
        "            \"food\": 4,\n",
        "            \"urban\": 3,\n",
        "        },\n",
        "    },\n",
        "]\n",
        "\n",
        "dims = [\"nightlife\", \"adventure\", \"shopping\", \"food\", \"urban\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04458e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c04458e1",
        "outputId": "d6bbabba-a635-473a-927e-aecdb6b303c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group average preference weights: {'nightlife': 0.18043956043956041, 'adventure': 0.17626373626373626, 'shopping': 0.12996336996336993, 'food': 0.2551648351648351, 'urban': 0.2581684981684982}\n",
            "Group avg budget: 3850.0 min budget: 500.0\n"
          ]
        }
      ],
      "source": [
        "# ---------- Step 1: normalize each person's weights ----------\n",
        "def normalize_weights(w_dict, dims):\n",
        "    total = sum(w_dict[d] for d in dims)\n",
        "    if total == 0:\n",
        "        return {d: 1.0 / len(dims) for d in dims}\n",
        "    return {d: w_dict[d] / total for d in dims}\n",
        "\n",
        "for m in group_members:\n",
        "    m[\"norm_weights\"] = normalize_weights(m[\"preference_weights\"], dims)\n",
        "\n",
        "# ---------- Step 2: aggregate to group-level average preferences ----------\n",
        "group_weights = {\n",
        "    d: float(np.mean([m[\"norm_weights\"][d] for m in group_members]))\n",
        "    for d in dims\n",
        "}\n",
        "\n",
        "group_budgets = [m[\"total_budget\"] for m in group_members]\n",
        "group_budget_avg = float(np.mean(group_budgets))\n",
        "group_budget_min = float(np.min(group_budgets))\n",
        "\n",
        "print(\"Group average preference weights:\", group_weights)\n",
        "print(\"Group avg budget:\", group_budget_avg, \"min budget:\", group_budget_min)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc7dc25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "ebc7dc25",
        "outputId": "2af4e6a5-fd41-4bb4-8867-3dbec64a1602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>avg_tag_nightlife</th>\n",
              "      <th>avg_tag_adventure</th>\n",
              "      <th>avg_tag_shopping</th>\n",
              "      <th>avg_tag_food</th>\n",
              "      <th>avg_tag_urban</th>\n",
              "      <th>avg_price_proxy</th>\n",
              "      <th>n_places</th>\n",
              "      <th>vibe_nightlife</th>\n",
              "      <th>vibe_adventure</th>\n",
              "      <th>vibe_shopping</th>\n",
              "      <th>vibe_food</th>\n",
              "      <th>vibe_urban</th>\n",
              "      <th>cost_index</th>\n",
              "      <th>typical_cost_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Boise</td>\n",
              "      <td>0.175230</td>\n",
              "      <td>0.035222</td>\n",
              "      <td>0.014111</td>\n",
              "      <td>0.660262</td>\n",
              "      <td>0.115175</td>\n",
              "      <td>27.554745</td>\n",
              "      <td>150</td>\n",
              "      <td>0.175230</td>\n",
              "      <td>0.035222</td>\n",
              "      <td>0.014111</td>\n",
              "      <td>0.660262</td>\n",
              "      <td>0.115175</td>\n",
              "      <td>0.544328</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>New Orleans</td>\n",
              "      <td>0.130167</td>\n",
              "      <td>0.021111</td>\n",
              "      <td>0.040119</td>\n",
              "      <td>0.499865</td>\n",
              "      <td>0.308738</td>\n",
              "      <td>29.243697</td>\n",
              "      <td>150</td>\n",
              "      <td>0.130167</td>\n",
              "      <td>0.021111</td>\n",
              "      <td>0.040119</td>\n",
              "      <td>0.499865</td>\n",
              "      <td>0.308738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Philadelphia</td>\n",
              "      <td>0.104857</td>\n",
              "      <td>0.043333</td>\n",
              "      <td>0.063730</td>\n",
              "      <td>0.577802</td>\n",
              "      <td>0.210278</td>\n",
              "      <td>25.537190</td>\n",
              "      <td>150</td>\n",
              "      <td>0.104857</td>\n",
              "      <td>0.043333</td>\n",
              "      <td>0.063730</td>\n",
              "      <td>0.577802</td>\n",
              "      <td>0.210278</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tampa</td>\n",
              "      <td>0.132421</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.039370</td>\n",
              "      <td>0.630320</td>\n",
              "      <td>0.157889</td>\n",
              "      <td>26.753731</td>\n",
              "      <td>150</td>\n",
              "      <td>0.132421</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.039370</td>\n",
              "      <td>0.630320</td>\n",
              "      <td>0.157889</td>\n",
              "      <td>0.328218</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tucson</td>\n",
              "      <td>0.106984</td>\n",
              "      <td>0.045000</td>\n",
              "      <td>0.080857</td>\n",
              "      <td>0.530770</td>\n",
              "      <td>0.236389</td>\n",
              "      <td>25.646552</td>\n",
              "      <td>150</td>\n",
              "      <td>0.106984</td>\n",
              "      <td>0.045000</td>\n",
              "      <td>0.080857</td>\n",
              "      <td>0.530770</td>\n",
              "      <td>0.236389</td>\n",
              "      <td>0.029505</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           city  avg_tag_nightlife  avg_tag_adventure  avg_tag_shopping  \\\n",
              "0         Boise           0.175230           0.035222          0.014111   \n",
              "1   New Orleans           0.130167           0.021111          0.040119   \n",
              "2  Philadelphia           0.104857           0.043333          0.063730   \n",
              "3         Tampa           0.132421           0.040000          0.039370   \n",
              "4        Tucson           0.106984           0.045000          0.080857   \n",
              "\n",
              "   avg_tag_food  avg_tag_urban  avg_price_proxy  n_places  vibe_nightlife  \\\n",
              "0      0.660262       0.115175        27.554745       150        0.175230   \n",
              "1      0.499865       0.308738        29.243697       150        0.130167   \n",
              "2      0.577802       0.210278        25.537190       150        0.104857   \n",
              "3      0.630320       0.157889        26.753731       150        0.132421   \n",
              "4      0.530770       0.236389        25.646552       150        0.106984   \n",
              "\n",
              "   vibe_adventure  vibe_shopping  vibe_food  vibe_urban  cost_index  \\\n",
              "0        0.035222       0.014111   0.660262    0.115175    0.544328   \n",
              "1        0.021111       0.040119   0.499865    0.308738    1.000000   \n",
              "2        0.043333       0.063730   0.577802    0.210278    0.000000   \n",
              "3        0.040000       0.039370   0.630320    0.157889    0.328218   \n",
              "4        0.045000       0.080857   0.530770    0.236389    0.029505   \n",
              "\n",
              "  typical_cost_level  \n",
              "0             medium  \n",
              "1               high  \n",
              "2                low  \n",
              "3                low  \n",
              "4                low  "
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dims = [\"nightlife\", \"adventure\", \"shopping\", \"food\", \"urban\"]\n",
        "\n",
        "for m in group_members:\n",
        "    m[\"norm_weights\"] = normalize_weights(m[\"preference_weights\"], dims)\n",
        "\n",
        "group_weights = {\n",
        "    d: float(np.mean([m[\"norm_weights\"][d] for m in group_members]))\n",
        "    for d in dims\n",
        "}\n",
        "\n",
        "activities_df = pd.read_csv(\"activities.csv\")\n",
        "\n",
        "tag_cols = [\"tag_nightlife\", \"tag_adventure\", \"tag_shopping\", \"tag_food\", \"tag_urban\"]\n",
        "\n",
        "price_map = {1: 15, 2: 30, 3: 50, 4: 80}  # simple heuristic\n",
        "activities_df[\"price_proxy\"] = activities_df[\"price_level\"].map(price_map)\n",
        "\n",
        "# Aggregate over activities to get city-level vibes & costs\n",
        "city_stats = (\n",
        "    activities_df\n",
        "    .groupby(\"city\")\n",
        "    .agg(\n",
        "        avg_tag_nightlife=(\"tag_nightlife\", \"mean\"),\n",
        "        avg_tag_adventure=(\"tag_adventure\", \"mean\"),\n",
        "        avg_tag_shopping=(\"tag_shopping\", \"mean\"),\n",
        "        avg_tag_food=(\"tag_food\", \"mean\"),\n",
        "        avg_tag_urban=(\"tag_urban\", \"mean\"),\n",
        "        avg_price_proxy=(\"price_proxy\", \"mean\"),\n",
        "        n_places=(\"business_id\", \"nunique\"),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Filter out cities that have too few places to be meaningful\n",
        "city_stats = city_stats[city_stats[\"n_places\"] >= 20].copy()\n",
        "\n",
        "# Build a 5D vibe vector for each city\n",
        "for d in dims:\n",
        "    city_stats[f\"vibe_{d}\"] = city_stats[f\"avg_tag_{d}\"]\n",
        "\n",
        "# Normalize vibes per city (optional but nice)\n",
        "vibe_cols = [f\"vibe_{d}\" for d in dims]\n",
        "city_stats[\"vibe_sum\"] = city_stats[vibe_cols].sum(axis=1)\n",
        "city_stats[vibe_cols] = city_stats[vibe_cols].div(city_stats[\"vibe_sum\"], axis=0)\n",
        "city_stats.drop(columns=[\"vibe_sum\"], inplace=True)\n",
        "\n",
        "# Compute a 0–1 cost_index from avg_price_proxy across cities\n",
        "min_cost = city_stats[\"avg_price_proxy\"].min()\n",
        "max_cost = city_stats[\"avg_price_proxy\"].max()\n",
        "city_stats[\"cost_index\"] = (city_stats[\"avg_price_proxy\"] - min_cost) / (max_cost - min_cost + 1e-9)\n",
        "\n",
        "def cost_level(x):\n",
        "    if x < 0.33:\n",
        "        return \"low\"\n",
        "    elif x < 0.66:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"high\"\n",
        "\n",
        "city_stats[\"typical_cost_level\"] = city_stats[\"cost_index\"].apply(cost_level)\n",
        "\n",
        "city_stats.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "54a1f982",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54a1f982",
        "outputId": "c8c67402-5ed3-4f39-8f31-39b89dee1220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked cities based on activities only:\n",
            "Philadelphia: combined=0.237, vibe=0.237, cost_index=0.00, avg_price_proxy=25.5, cost_level=low, n_places=150\n",
            "Tucson: combined=0.230, vibe=0.234, cost_index=0.03, avg_price_proxy=25.6, cost_level=low, n_places=150\n",
            "Tampa: combined=0.199, vibe=0.238, cost_index=0.33, avg_price_proxy=26.8, cost_level=low, n_places=150\n",
            "Boise: combined=0.179, vibe=0.238, cost_index=0.54, avg_price_proxy=27.6, cost_level=medium, n_places=150\n",
            "New Orleans: combined=0.150, vibe=0.240, cost_index=1.00, avg_price_proxy=29.2, cost_level=high, n_places=150\n",
            "\n",
            "Best city: Philadelphia\n"
          ]
        }
      ],
      "source": [
        "def score_city_row(row, group_weights, lambda_cost=0.6):\n",
        "    # City vibe vector\n",
        "    city_vec = np.array([row[f\"vibe_{d}\"] for d in dims], dtype=float)\n",
        "    # Group preference vector\n",
        "    w_vec = np.array([group_weights[d] for d in dims], dtype=float)\n",
        "\n",
        "    vibe_score = float((city_vec * w_vec).sum())\n",
        "    cost_index = float(row[\"cost_index\"])\n",
        "\n",
        "    # Penalize expensive cities a bit\n",
        "    cost_penalty = 1.0 / (1.0 + lambda_cost * cost_index)\n",
        "    combined_score = vibe_score * cost_penalty\n",
        "\n",
        "    return vibe_score, combined_score\n",
        "\n",
        "city_scores = []\n",
        "for _, row in city_stats.iterrows():\n",
        "    vibe, combined = score_city_row(row, group_weights)\n",
        "    city_scores.append({\n",
        "        \"city\": row[\"city\"],\n",
        "        \"vibe_score\": vibe,\n",
        "        \"combined_score\": combined,\n",
        "        \"avg_price_proxy\": float(row[\"avg_price_proxy\"]),\n",
        "        \"cost_index\": float(row[\"cost_index\"]),\n",
        "        \"typical_cost_level\": row[\"typical_cost_level\"],\n",
        "        \"n_places\": int(row[\"n_places\"]),\n",
        "        \"vibe_tags\": {d: float(row[f\"vibe_{d}\"]) for d in dims},\n",
        "    })\n",
        "\n",
        "city_scores_sorted = sorted(city_scores, key=lambda x: x[\"combined_score\"], reverse=True)\n",
        "\n",
        "print(\"Ranked cities based on activities only:\")\n",
        "for c in city_scores_sorted[:10]:\n",
        "    print(\n",
        "        f\"{c['city']}: combined={c['combined_score']:.3f}, \"\n",
        "        f\"vibe={c['vibe_score']:.3f}, \"\n",
        "        f\"cost_index={c['cost_index']:.2f}, \"\n",
        "        f\"avg_price_proxy={c['avg_price_proxy']:.1f}, \"\n",
        "        f\"cost_level={c['typical_cost_level']}, \"\n",
        "        f\"n_places={c['n_places']}\"\n",
        "    )\n",
        "\n",
        "best_city = city_scores_sorted[0]\n",
        "print(\"\\nBest city:\", best_city[\"city\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5d1941",
      "metadata": {
        "id": "fe5d1941"
      },
      "source": [
        "#### LLM Layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "962d4de7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "962d4de7",
        "outputId": "c0b66ffa-f832-47a2-ca1c-7fdb8c9bb001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"group_profile\": {\n",
            "    \"origin_cities\": [\n",
            "      \"Atlanta\",\n",
            "      \"Boston\",\n",
            "      \"Chicago\",\n",
            "      \"Dallas\",\n",
            "      \"Seattle\"\n",
            "    ],\n",
            "    \"budgets\": {\n",
            "      \"per_person\": [\n",
            "        {\n",
            "          \"name\": \"Alice\",\n",
            "          \"total_budget\": 900\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"Ben\",\n",
            "          \"total_budget\": 750\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"Carla\",\n",
            "          \"total_budget\": 650\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"Deepak\",\n",
            "          \"total_budget\": 500\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"Emma\",\n",
            "          \"total_budget\": 1100\n",
            "        }\n",
            "      ],\n",
            "      \"average_budget\": 780.0,\n",
            "      \"min_budget\": 500.0\n",
            "    },\n",
            "    \"average_preference_weights\": {\n",
            "      \"nightlife\": 0.18043956043956041,\n",
            "      \"adventure\": 0.17626373626373626,\n",
            "      \"shopping\": 0.12996336996336993,\n",
            "      \"food\": 0.2551648351648351,\n",
            "      \"urban\": 0.2581684981684982\n",
            "    }\n",
            "  },\n",
            "  \"city_scores\": [\n",
            "    {\n",
            "      \"city\": \"Philadelphia\",\n",
            "      \"vibe_score\": 0.2365628030699459,\n",
            "      \"combined_score\": 0.2365628030699459,\n",
            "      \"avg_price_proxy\": 25.537190082644628,\n",
            "      \"cost_index\": 0.0,\n",
            "      \"typical_cost_level\": \"low\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.10485714285714286,\n",
            "        \"adventure\": 0.043333333333333335,\n",
            "        \"shopping\": 0.06373015873015873,\n",
            "        \"food\": 0.5778015873015873,\n",
            "        \"urban\": 0.21027777777777779\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"Tucson\",\n",
            "      \"vibe_score\": 0.2342064672364672,\n",
            "      \"combined_score\": 0.2301323910221355,\n",
            "      \"avg_price_proxy\": 25.646551724137932,\n",
            "      \"cost_index\": 0.02950530776535966,\n",
            "      \"typical_cost_level\": \"low\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.10698412698412699,\n",
            "        \"adventure\": 0.045,\n",
            "        \"shopping\": 0.08085714285714285,\n",
            "        \"food\": 0.5307698412698413,\n",
            "        \"urban\": 0.2363888888888889\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"Tampa\",\n",
            "      \"vibe_score\": 0.23765863984340174,\n",
            "      \"combined_score\": 0.1985567402134851,\n",
            "      \"avg_price_proxy\": 26.753731343283583,\n",
            "      \"cost_index\": 0.3282176804799384,\n",
            "      \"typical_cost_level\": \"low\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.13242063492063494,\n",
            "        \"adventure\": 0.04000000000000001,\n",
            "        \"shopping\": 0.039370370370370375,\n",
            "        \"food\": 0.6303201058201059,\n",
            "        \"urban\": 0.1578888888888889\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"Boise\",\n",
            "      \"vibe_score\": 0.23787085528228386,\n",
            "      \"combined_score\": 0.17930911145824802,\n",
            "      \"avg_price_proxy\": 27.554744525547445,\n",
            "      \"cost_index\": 0.5443276450350364,\n",
            "      \"typical_cost_level\": \"medium\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.17523015873015874,\n",
            "        \"adventure\": 0.03522222222222223,\n",
            "        \"shopping\": 0.014111111111111112,\n",
            "        \"food\": 0.6602619047619048,\n",
            "        \"urban\": 0.11517460317460318\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"New Orleans\",\n",
            "      \"vibe_score\": 0.23967678702250128,\n",
            "      \"combined_score\": 0.14979799190421889,\n",
            "      \"avg_price_proxy\": 29.243697478991596,\n",
            "      \"cost_index\": 0.9999999997302043,\n",
            "      \"typical_cost_level\": \"high\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.13016666666666665,\n",
            "        \"adventure\": 0.021111111111111112,\n",
            "        \"shopping\": 0.04011904761904762,\n",
            "        \"food\": 0.49986507936507935,\n",
            "        \"urban\": 0.3087380952380952\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Build the payload we'll send to the LLM\n",
        "decision_payload = {\n",
        "    \"group_profile\": {\n",
        "        \"origin_cities\": sorted({m[\"origin_city\"] for m in group_members}),\n",
        "        \"budgets\": {\n",
        "            \"per_person\": [\n",
        "                {\"name\": m[\"name\"], \"total_budget\": m[\"total_budget\"]}\n",
        "                for m in group_members\n",
        "            ],\n",
        "            \"average_budget\": group_budget_avg,\n",
        "            \"min_budget\": group_budget_min,\n",
        "        },\n",
        "        \"average_preference_weights\": group_weights,\n",
        "    },\n",
        "    \"city_scores\": city_scores_sorted,  # already sorted best→worst\n",
        "}\n",
        "\n",
        "print(json.dumps(decision_payload, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ccccbf50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ccccbf50",
        "outputId": "997ffd30-b283-4e02-e01a-aad7a7c4609e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.5 (from langchain-google-genai)\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (0.4.43)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-3.1.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, langchain-core, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.1.0 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-core-1.1.0 langchain-google-genai-3.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "2eb4f66d3ea541769cc580a08619a743",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "089ecf12",
      "metadata": {
        "id": "089ecf12"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Set your Google AI key (best practice: use environment variable or .env)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAOPrSe5SsfO8nUSYNtEt9fx7uxzKDeL3Q\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-lite\",  # as requested\n",
        "    temperature=0.3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86dbd6dc",
      "metadata": {
        "id": "86dbd6dc",
        "outputId": "3a01d835-bab7-45a2-d544-ef65206ca194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Philadelphia is the top choice for your group! It has a great vibe that aligns with your interests and offers a low cost of living, making it an excellent fit for everyone's budget.\n"
          ]
        }
      ],
      "source": [
        "system_instructions = \"\"\"\n",
        "You are a helpful trip-planning assistant.\n",
        "You will receive a JSON payload with:\n",
        "- group_profile (preferences, budgets, origin cities)\n",
        "- city_scores (candidate cities with vibe_score, combined_score, avg_price_proxy, cost_index, typical_cost_level)\n",
        "\n",
        "Use the combined_score to pick the best city.\n",
        "Explain the choice in 2–3 sentences in friendly, simple language.\n",
        "Mention why this city fits the group's interests AND how its cost level fits their budgets.\n",
        "Do NOT print the raw JSON or raw numeric scores.\n",
        "\"\"\"\n",
        "\n",
        "user_content = \"Here is the JSON payload:\\n\" + json.dumps(decision_payload, indent=2)\n",
        "\n",
        "prompt = system_instructions.strip() + \"\\n\\n\" + user_content\n",
        "\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02aba8dc",
      "metadata": {
        "id": "02aba8dc"
      },
      "source": [
        "### Search Flights and Hotels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45fc700f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45fc700f",
        "outputId": "e842d39d-3fa8-45da-b3ad-1004516b2057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flights: [{'price': 220, 'airline': 'Delta', 'depart_time': '2025-03-14T08:30', 'arrive_time': '2025-03-14T11:10', 'legs': 1}, {'price': 260, 'airline': 'United', 'depart_time': '2025-03-14T13:45', 'arrive_time': '2025-03-14T16:30', 'legs': 1}, {'price': 180, 'airline': 'Frontier', 'depart_time': '2025-03-14T06:00', 'arrive_time': '2025-03-14T09:00', 'legs': 1}]\n",
            "Hotels: [{'price_per_night': 120, 'name': 'Central Inn', 'rating': 4.1, 'area': 'Downtown'}, {'price_per_night': 180, 'name': 'Riverside Hotel', 'rating': 4.5, 'area': 'Waterfront'}, {'price_per_night': 90, 'name': 'Budget Stay', 'rating': 3.4, 'area': 'Suburbs'}]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def search_hotels(city, checkin, checkout, guests=2, max_price=None, min_rating=3.0):\n",
        "    \"\"\"Dummy hotel search – replace later with real API.\"\"\"\n",
        "    hotels = [\n",
        "        {\"price_per_night\": 120, \"name\": \"Central Inn\", \"rating\": 4.1, \"area\": \"Downtown\"},\n",
        "        {\"price_per_night\": 180, \"name\": \"Riverside Hotel\", \"rating\": 4.5, \"area\": \"Waterfront\"},\n",
        "        {\"price_per_night\": 90,  \"name\": \"Budget Stay\", \"rating\": 3.4, \"area\": \"Suburbs\"},\n",
        "    ]\n",
        "    if max_price is not None:\n",
        "        hotels = [h for h in hotels if h[\"price_per_night\"] <= max_price]\n",
        "    hotels = [h for h in hotels if h[\"rating\"] >= min_rating]\n",
        "    return hotels\n",
        "\n",
        "\n",
        "# Example usage\n",
        "flights = search_flights(\"ORD\", \"MSY\", \"2025-03-14\", \"2025-03-16\")\n",
        "hotels = search_hotels(\"New Orleans\", \"2025-03-14\", \"2025-03-16\", max_price=200)\n",
        "\n",
        "print(\"Flights:\", flights)\n",
        "print(\"Hotels:\", hotels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d501e3aa",
      "metadata": {
        "id": "d501e3aa"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Make sure GOOGLE_API_KEY is set in the environment\n",
        "# import os\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_REAL_KEY_HERE\"\n",
        "\n",
        "# Global DataFrame of activities (load this once at notebook start)\n",
        "activities_df = pd.read_csv(\"activities.csv\")\n",
        "\n",
        "DIMS = [\"nightlife\", \"adventure\", \"shopping\", \"food\", \"urban\"]\n",
        "TAG_COLS = [f\"tag_{d}\" for d in DIMS]\n",
        "\n",
        "\n",
        "def normalize_weights(w_dict: Dict[str, float], dims: List[str]) -> Dict[str, float]:\n",
        "    total = sum(w_dict.get(d, 0.0) for d in dims)\n",
        "    if total <= 0:\n",
        "        return {d: 1.0 / len(dims) for d in dims}\n",
        "    return {d: w_dict.get(d, 0.0) / total for d in dims}\n",
        "\n",
        "\n",
        "def compute_base_scores_for_city(\n",
        "    city: str,\n",
        "    group_members: List[Dict[str, Any]],\n",
        "    top_k_activities: int = 10,\n",
        "    min_stars: float = 3.5,\n",
        "    min_review_count: int = 30,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Filter activities for the city, compute base enjoyment/value scores per user and per activity,\n",
        "    and return the top K activities by group value.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Normalize user preference weights\n",
        "    for m in group_members:\n",
        "        m[\"norm_weights\"] = normalize_weights(m[\"preference_weights\"], DIMS)\n",
        "\n",
        "    # 2) Filter activities for the chosen city & quality\n",
        "    city_df = activities_df[\n",
        "        (activities_df[\"city\"] == city)\n",
        "        & (activities_df[\"stars\"] >= min_stars)\n",
        "        & (activities_df[\"review_count\"] >= min_review_count)\n",
        "    ].copy()\n",
        "\n",
        "    if city_df.empty:\n",
        "        raise ValueError(f\"No activities found for city={city} with current filters.\")\n",
        "\n",
        "    # Ensure price_proxy exists; if not, create from price_level\n",
        "    if \"price_proxy\" not in city_df.columns:\n",
        "        price_map = {1: 15, 2: 30, 3: 50, 4: 80}\n",
        "        city_df[\"price_proxy\"] = city_df[\"price_level\"].map(price_map)\n",
        "\n",
        "    # 3) Compute base enjoyment + value per user and group\n",
        "    #    We'll compute a group_value score per activity and keep that for ranking.\n",
        "    group_values = []\n",
        "    per_user_scores: Dict[str, Dict[str, float]] = {\n",
        "        m[\"id\"]: {} for m in group_members\n",
        "    }  # user_id -> {business_id: value_score}\n",
        "\n",
        "    for idx, row in city_df.iterrows():\n",
        "        biz_id = row[\"business_id\"]\n",
        "        tags_vec = np.array([row[col] for col in TAG_COLS], dtype=float)\n",
        "        price = float(row[\"price_proxy\"]) if not pd.isna(row[\"price_proxy\"]) else 1.0\n",
        "\n",
        "        user_values = []\n",
        "        for m in group_members:\n",
        "            w_vec = np.array([m[\"norm_weights\"][d] for d in DIMS], dtype=float)\n",
        "            base_enjoyment = float((w_vec * tags_vec).sum())\n",
        "            value_score = base_enjoyment / max(price, 1e-6)\n",
        "            per_user_scores[m[\"id\"]][biz_id] = value_score\n",
        "            user_values.append(value_score)\n",
        "\n",
        "        group_value = float(np.mean(user_values))\n",
        "        group_values.append((biz_id, group_value))\n",
        "\n",
        "    # 4) Select top K activities by group value\n",
        "    group_values_sorted = sorted(group_values, key=lambda x: x[1], reverse=True)\n",
        "    top_biz_ids = [biz_id for biz_id, _ in group_values_sorted[:top_k_activities]]\n",
        "\n",
        "    top_city_df = city_df[city_df[\"business_id\"].isin(top_biz_ids)].copy()\n",
        "\n",
        "    return {\n",
        "        \"city_df\": top_city_df,\n",
        "        \"per_user_scores\": per_user_scores,\n",
        "        \"top_biz_ids\": top_biz_ids,\n",
        "    }\n",
        "\n",
        "\n",
        "def build_llm_for_reranking(temperature: float = 0.3) -> ChatGoogleGenerativeAI:\n",
        "    \"\"\"Create a Gemini LLM instance for reranking.\"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash-lite\",\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "\n",
        "def rerank_with_gemini(\n",
        "    city: str,\n",
        "    group_members: List[Dict[str, Any]],\n",
        "    base_info: Dict[str, Any],\n",
        "    llm: ChatGoogleGenerativeAI,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    For each user and each of the top activities, call Gemini to get:\n",
        "      - adjusted_enjoyment_score\n",
        "      - recommended_time_of_day\n",
        "      - note\n",
        "\n",
        "    Returns a list of dicts: one entry per (user, activity).\n",
        "    \"\"\"\n",
        "\n",
        "    city_df = base_info[\"city_df\"]\n",
        "    per_user_scores = base_info[\"per_user_scores\"]\n",
        "    top_biz_ids = base_info[\"top_biz_ids\"]\n",
        "\n",
        "    # We'll process per-user, sending all top activities in one call per user\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for m in group_members:\n",
        "        # Handle missing total_budget gracefully (use default or get from budget field)\n",
        "        total_budget = m.get(\"total_budget\") or m.get(\"budget\")\n",
        "        if total_budget is None:\n",
        "            raise ValueError(f\"Missing 'total_budget' field for user {m.get('id', 'unknown')}. Each group member must have a 'total_budget' field.\")\n",
        "        \n",
        "        user_profile = {\n",
        "            \"id\": m[\"id\"],\n",
        "            \"name\": m[\"name\"],\n",
        "            \"total_budget\": total_budget,\n",
        "            \"norm_weights\": m[\"norm_weights\"],\n",
        "            \"notes\": m.get(\"notes\", \"\"),\n",
        "        }\n",
        "\n",
        "        # Build concise activity list\n",
        "        activities_payload = []\n",
        "        for _, row in city_df.iterrows():\n",
        "            biz_id = row[\"business_id\"]\n",
        "            activities_payload.append({\n",
        "                \"business_id\": biz_id,\n",
        "                \"name\": row[\"name\"],\n",
        "                \"stars\": float(row[\"stars\"]),\n",
        "                \"review_count\": int(row[\"review_count\"]),\n",
        "                \"price_proxy\": float(row[\"price_proxy\"]),\n",
        "                \"value_score\": per_user_scores[m[\"id\"]].get(biz_id, 0.0),\n",
        "                \"tags5\": {\n",
        "                    d: float(row[f\"tag_{d}\"]) for d in DIMS\n",
        "                },\n",
        "            })\n",
        "\n",
        "        # Prepare prompt\n",
        "        system_instructions = \"\"\"\n",
        "You are a trip personalization model.\n",
        "You receive a single user's profile and a list of candidate activities in one city.\n",
        "\n",
        "For each activity, you must produce:\n",
        "- adjusted_enjoyment_score (0–10, float)\n",
        "- recommended_time_of_day (\"morning\" | \"afternoon\" | \"evening\" | \"late night\")\n",
        "- note: one short sentence explaining why this user would or would not like it.\n",
        "\n",
        "Consider:\n",
        "- The user's normalized weights per dimension (nightlife, adventure, shopping, food, urban).\n",
        "- The user's free-text notes.\n",
        "- The activity's tag scores, rating, review_count, and price_proxy.\n",
        "- The base value_score as a hint, but you can override it.\n",
        "\n",
        "Return ONLY valid JSON in this exact format:\n",
        "{\n",
        "  \"user_id\": \"...\",\n",
        "  \"city\": \"...\",\n",
        "  \"results\": [\n",
        "    {\n",
        "      \"business_id\": \"...\",\n",
        "      \"adjusted_enjoyment_score\": 0.0,\n",
        "      \"recommended_time_of_day\": \"evening\",\n",
        "      \"note\": \"...\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "        user_payload = {\n",
        "            \"user_profile\": user_profile,\n",
        "            \"city\": city,\n",
        "            \"activities\": activities_payload,\n",
        "        }\n",
        "\n",
        "        prompt = system_instructions.strip() + \"\\n\\nUser + activities JSON:\\n\" + json.dumps(\n",
        "            user_payload, indent=2\n",
        "        )\n",
        "\n",
        "        response = llm.invoke(prompt)\n",
        "        try:\n",
        "            parsed = json.loads(response.content)\n",
        "        except json.JSONDecodeError:\n",
        "            # Fallback: wrap everything in a minimal structure or log error\n",
        "            # For now, skip this user if parsing fails\n",
        "            print(f\"JSON parsing failed for user {m['id']}: {response.content[:200]}\")\n",
        "            continue\n",
        "\n",
        "        # Append per-activity results, but enforce schema\n",
        "        for item in parsed.get(\"results\", []):\n",
        "            results.append({\n",
        "                \"user_id\": parsed.get(\"user_id\", m[\"id\"]),\n",
        "                \"city\": parsed.get(\"city\", city),\n",
        "                \"business_id\": item[\"business_id\"],\n",
        "                \"adjusted_enjoyment_score\": float(item[\"adjusted_enjoyment_score\"]),\n",
        "                \"recommended_time_of_day\": item[\"recommended_time_of_day\"],\n",
        "                \"note\": item[\"note\"],\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ---------- The main tool-like function ----------\n",
        "\n",
        "def find_and_rerank_activities_tool(input_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Input JSON:\n",
        "    {\n",
        "      \"city\": \"New Orleans\",\n",
        "      \"group_members\": [\n",
        "        {\n",
        "          \"id\": \"u1\",\n",
        "          \"name\": \"Alice\",\n",
        "          \"total_budget\": 900,\n",
        "          \"preference_weights\": {...},\n",
        "          \"notes\": \"...\"\n",
        "        },\n",
        "        ...\n",
        "      ],\n",
        "      \"top_k\": 10   # optional\n",
        "    }\n",
        "\n",
        "    Output JSON:\n",
        "    {\n",
        "      \"city\": \"New Orleans\",\n",
        "      \"activities\": [\n",
        "        {\n",
        "          \"user_id\": \"u1\",\n",
        "          \"business_id\": \"abc123\",\n",
        "          \"adjusted_enjoyment_score\": 8.8,\n",
        "          \"recommended_time_of_day\": \"evening\",\n",
        "          \"note\": \"Great for nightlife lovers...\"\n",
        "        },\n",
        "        ...\n",
        "      ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    data = json.loads(input_json)\n",
        "    city = data[\"city\"]\n",
        "    group_members = data[\"group_members\"]\n",
        "    top_k = data.get(\"top_k\", 5)\n",
        "\n",
        "    # Validate required fields in group_members\n",
        "    required_fields = [\"id\", \"name\", \"total_budget\", \"preference_weights\"]\n",
        "    for i, member in enumerate(group_members):\n",
        "        missing = [field for field in required_fields if field not in member]\n",
        "        if missing:\n",
        "            return json.dumps({\n",
        "                \"error\": f\"Missing required fields for group_members[{i}]: {missing}. Each member must have: id, name, total_budget, preference_weights\"\n",
        "            })\n",
        "\n",
        "    # 1) Compute base scores & pick top K activities\n",
        "    base_info = compute_base_scores_for_city(city, group_members, top_k_activities=top_k)\n",
        "\n",
        "    # 2) LLM rerank/enrich for each user-activity pair\n",
        "    llm = build_llm_for_reranking()\n",
        "    reranked = rerank_with_gemini(city, group_members, base_info, llm)\n",
        "\n",
        "    output = {\n",
        "        \"city\": city,\n",
        "        \"activities\": reranked,\n",
        "    }\n",
        "    return json.dumps(output, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8751675c",
      "metadata": {
        "id": "8751675c"
      },
      "source": [
        "### Fairness score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4078c917",
      "metadata": {
        "id": "4078c917"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def affordability_component(mean_ratio: float) -> float:\n",
        "    # 0.6 -> 1.0, 1.0 -> 0.5, 1.4 -> 0.0\n",
        "    if mean_ratio <= 0.6:\n",
        "        return 1.0\n",
        "    if mean_ratio >= 1.4:\n",
        "        return 0.0\n",
        "    return 1.0 - (mean_ratio - 0.6) / (1.4 - 0.6)\n",
        "\n",
        "\n",
        "def equality_component(std_ratio: float) -> float:\n",
        "    # 0.05 -> 1.0, 0.25 -> 0.0\n",
        "    if std_ratio <= 0.05:\n",
        "        return 1.0\n",
        "    if std_ratio >= 0.25:\n",
        "        return 0.0\n",
        "    return 1.0 - (std_ratio - 0.05) / (0.25 - 0.05)\n",
        "\n",
        "\n",
        "def affordability_label(r: float) -> str:\n",
        "    if r <= 0.6:\n",
        "        return \"comfortable\"\n",
        "    elif r <= 1.0:\n",
        "        return \"stretch\"\n",
        "    elif r <= 1.3:\n",
        "        return \"risky\"\n",
        "    else:\n",
        "        return \"not_recommended\"\n",
        "\n",
        "\n",
        "def compute_fairness_summary(group_members):\n",
        "    \"\"\"\n",
        "    Each member dict must have:\n",
        "      - name\n",
        "      - total_budget\n",
        "      - flight_price\n",
        "      - hotel_share\n",
        "      - activities_spend\n",
        "    Returns: {\n",
        "      \"trip_fairness_score\": 0-100,\n",
        "      \"mean_ratio\": ...,\n",
        "      \"std_ratio\": ...,\n",
        "      \"per_person\": [...]\n",
        "    }\n",
        "    \"\"\"\n",
        "    ratios = []\n",
        "    per_person = []\n",
        "\n",
        "    for p in group_members:\n",
        "        trip_cost = p[\"flight_price\"] + p[\"hotel_share\"] + p[\"activities_spend\"]\n",
        "        r = trip_cost / p[\"total_budget\"]\n",
        "        label = affordability_label(r)\n",
        "\n",
        "        per_person.append({\n",
        "            \"name\": p[\"name\"],\n",
        "            \"trip_cost\": round(trip_cost, 2),\n",
        "            \"budget\": p[\"total_budget\"],\n",
        "            \"affordability_ratio\": round(r, 3),\n",
        "            \"affordability_label\": label,\n",
        "        })\n",
        "        ratios.append(min(r, 2.0))  # clamp\n",
        "\n",
        "    ratios = np.array(ratios, dtype=float)\n",
        "    mean_ratio = float(ratios.mean())\n",
        "    std_ratio = float(ratios.std())\n",
        "\n",
        "    aff_comp = affordability_component(mean_ratio)\n",
        "    eq_comp  = equality_component(std_ratio)\n",
        "\n",
        "    fairness_score = 100 * (0.6 * aff_comp + 0.4 * eq_comp)\n",
        "    fairness_score = max(0.0, min(100.0, fairness_score))\n",
        "\n",
        "    return {\n",
        "        \"trip_fairness_score\": round(fairness_score, 1),\n",
        "        \"mean_ratio\": round(mean_ratio, 3),\n",
        "        \"std_ratio\": round(std_ratio, 3),\n",
        "        \"per_person\": per_person,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6b3dc0",
      "metadata": {
        "id": "1f6b3dc0"
      },
      "source": [
        "### Travel Agent LangChain part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4297ee44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "4297ee44",
        "outputId": "1c61ee3b-f33c-4612-ab5d-0a5476693287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.43)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 3.1.0 requires langchain-core<2.0.0,>=1.0.5, but you have langchain-core 0.3.80 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.80\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "88b8e63deb2e4dba89c9bf95dbd02d9c",
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fe9d0f1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fe9d0f1c",
        "outputId": "038152d5-fffa-4025-b682-c51d53d57124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain>=0.3.0 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain>=0.3.0\n",
            "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: langchain-google-genai>=0.1.0 in /usr/local/lib/python3.12/dist-packages (3.1.0)\n",
            "Collecting langchain-core<2.0.0,>=1.0.6 (from langchain>=0.3.0)\n",
            "  Using cached langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.2 (from langchain>=0.3.0)\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.3.0) (2.11.10)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai>=0.1.0) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai>=0.1.0) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (0.4.43)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (4.15.0)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain>=0.3.0)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain>=0.3.0)\n",
            "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain>=0.3.0)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.3.0) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (2.32.4)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (3.0.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain>=0.3.0) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai>=0.1.0) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain>=0.3.0) (1.3.1)\n",
            "Downloading langchain-1.0.8-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed langchain-1.0.8 langchain-core-1.1.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f9d3bd8c7df544d78a5aa0f93e547014",
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_core"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U \"langchain>=0.3.0\" \"langchain-google-genai>=0.1.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375f8fd0",
      "metadata": {
        "id": "375f8fd0",
        "outputId": "6c030b8f-a896-45c3-d1db-a2ba28548e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /Users/manoja/miniconda/lib/python3.13/site-packages (25.3)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f83bb981",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.11-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langgraph) (0.3.80)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langgraph) (2.12.4)\n",
            "Collecting xxhash>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.6.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.1->langgraph) (0.4.37)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.1->langgraph) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.1->langgraph) (23.2)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp39-cp39-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.0.0)\n",
            "Requirement already satisfied: certifi in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (2.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.31.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/manoja/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.1.3)\n",
            "Downloading langgraph-0.6.11-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.5-py3-none-any.whl (28 kB)\n",
            "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "Downloading xxhash-3.6.0-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
            "Downloading ormsgpack-1.11.0-cp39-cp39-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.0/368.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.11 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.6.5 langgraph-sdk-0.2.9 ormsgpack-1.11.0 xxhash-3.6.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langgraph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67457e6",
      "metadata": {},
      "source": [
        "## Clean Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "81a59d1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# AI TRIP PLANNER - CLEAN WORKING VERSION\n",
        "# ============================================================================\n",
        "# This file contains ONLY the working code from your notebook, in order.\n",
        "# No debug cells, no failed attempts - just what actually works!\n",
        "# ============================================================================\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# SECTION 1: IMPORTS\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "from langchain.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.prebuilt import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ec9e2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# SECTION 2: SAMPLE DATA & GROUP SETUP\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# 5 fake travelers with different tastes & budgets, origin cities, and date preferences\n",
        "group_members = [\n",
        "    {\n",
        "        \"id\": \"u1\",\n",
        "        \"name\": \"Alice\",\n",
        "        \"origin_city\": \"ORD\",  # Chicago O'Hare\n",
        "        \"total_budget\": 9000,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 1,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 1,\n",
        "            \"food\": 1,\n",
        "            \"urban\": 5,\n",
        "        },\n",
        "        \"notes\": \"Budget foodie, hates early mornings, loves walkable neighborhoods and speakeasies.\",\n",
        "        \"preferred_windows\": [\n",
        "            {\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"}   # Saturday-Sunday\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u2\",\n",
        "        \"name\": \"Ben\",\n",
        "        \"origin_city\": \"JFK\",  # New York JFK\n",
        "        \"total_budget\": 7000,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 2,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 1,\n",
        "            \"food\": 1,\n",
        "            \"urban\": 4,\n",
        "        },\n",
        "        \"notes\": \"Loves outdoor activities and casual spots, not into heavy nightlife.\",\n",
        "        \"preferred_windows\": [\n",
        "            {\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"},  # Saturday-Sunday (common)\n",
        "            {\"trip_start\": \"2025-12-13\", \"trip_end\": \"2025-12-14\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2026-01-10\", \"trip_end\": \"2026-01-11\"}   # Saturday-Sunday\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u3\",\n",
        "        \"name\": \"Carla\",\n",
        "        \"origin_city\": \"LAX\",  # Los Angeles\n",
        "        \"total_budget\": 6500,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 1,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 4,\n",
        "            \"food\": 1,\n",
        "            \"urban\": 5,\n",
        "        },\n",
        "        \"notes\": \"Enjoys shopping districts and museums, prefers quieter evenings.\",\n",
        "        \"preferred_windows\": [\n",
        "            {\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"},  # Saturday-Sunday (common)\n",
        "            {\"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"}   # Saturday-Sunday\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u4\",\n",
        "        \"name\": \"Deepak\",\n",
        "        \"origin_city\": \"SFO\",  # San Francisco\n",
        "        \"total_budget\": 700,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 1,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 2,\n",
        "            \"food\": 1,\n",
        "            \"urban\": 5,\n",
        "        },\n",
        "        \"notes\": \"On a tighter budget, okay with simple food, likes city walks and parks.\",\n",
        "        \"preferred_windows\": [\n",
        "            {\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"},  # Saturday-Sunday (common - 3rd person)\n",
        "            {\"trip_start\": \"2025-12-13\", \"trip_end\": \"2025-12-14\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2026-01-10\", \"trip_end\": \"2026-01-11\"}   # Saturday-Sunday\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"u5\",\n",
        "        \"name\": \"Emma\",\n",
        "        \"origin_city\": \"ATL\",  # Atlanta\n",
        "        \"total_budget\": 1100,\n",
        "        \"preference_weights\": {\n",
        "            \"nightlife\": 1,\n",
        "            \"adventure\": 5,\n",
        "            \"shopping\": 1,\n",
        "            \"food\": 2,\n",
        "            \"urban\": 5,\n",
        "        },\n",
        "        \"notes\": \"Happy to splurge a bit on nightlife and good food.\",\n",
        "        \"preferred_windows\": [\n",
        "            {\"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"},  # Saturday-Sunday\n",
        "            {\"trip_start\": \"2026-01-10\", \"trip_end\": \"2026-01-11\"}   # Saturday-Sunday\n",
        "        ]\n",
        "    },\n",
        "]\n",
        "\n",
        "DIMS = [\"nightlife\", \"adventure\", \"shopping\", \"food\", \"urban\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d9c5ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from langchain.tools import tool\n",
        "import json\n",
        "\n",
        "@tool\n",
        "def search_hotels_tool(\n",
        "    city: str,\n",
        "    checkin: str,\n",
        "    checkout: str,\n",
        "    max_price: Optional[float] = None,\n",
        "    min_rating: float = 0.0,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Minimal Google Hotels search via SerpAPI.\n",
        "    \n",
        "    Inputs:\n",
        "      - city: e.g. \"New Orleans\"\n",
        "      - checkin: \"YYYY-MM-DD\"\n",
        "      - checkout: \"YYYY-MM-DD\"\n",
        "      - max_price: optional upper bound in USD (not applied in this minimal version)\n",
        "      - min_rating: minimum rating (not strictly applied here – we mostly just expose fields)\n",
        "    \n",
        "    Returns:\n",
        "      JSON list of up to 5 hotels (filtered by max_price and min_rating):\n",
        "        [\n",
        "          {\n",
        "            \"name\": \"Hotel Name\",\n",
        "            \"rating\": 4.5,\n",
        "            \"area\": \"Downtown\",\n",
        "            \"price_per_night\": 120,\n",
        "          },\n",
        "          ...\n",
        "        ]\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import requests\n",
        "\n",
        "    try:\n",
        "        SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
        "        if not SERPAPI_KEY:\n",
        "            return json.dumps({\n",
        "                \"error\": \"SERPAPI_KEY not found in environment variables. Please set SERPAPI_KEY.\"\n",
        "            })\n",
        "\n",
        "        params = {\n",
        "            \"engine\": \"google_hotels\",\n",
        "            \"q\": city,\n",
        "            \"check_in_date\": checkin,\n",
        "            \"check_out_date\": checkout,\n",
        "            \"adults\": 2,\n",
        "            \"currency\": \"USD\",\n",
        "            \"hl\": \"en\",\n",
        "            \"gl\": \"us\",\n",
        "            \"api_key\": SERPAPI_KEY,\n",
        "        }\n",
        "\n",
        "        resp = requests.get(\"https://serpapi.com/search.json\", params=params, timeout=30)\n",
        "        if resp.status_code != 200:\n",
        "            return json.dumps({\"error\": f\"API Error: {resp.status_code}\", \"details\": resp.text[:500]})\n",
        "\n",
        "        data = resp.json()\n",
        "\n",
        "        # Debug: if you want to see the keys:\n",
        "        # return json.dumps({\"top_level_keys\": list(data.keys())}, indent=2)\n",
        "\n",
        "        # Hotels are often under \"properties\" or \"results\" / \"hotel_results\"\n",
        "        properties = data.get(\"properties\") or data.get(\"hotel_results\") or data.get(\"results\") or []\n",
        "\n",
        "        if not properties:\n",
        "            # For debugging, you might want to temporarily return the whole payload shape:\n",
        "            return json.dumps({\n",
        "                \"error\": \"No hotels found in response under properties/hotel_results/results\",\n",
        "                \"top_level_keys\": list(data.keys()),\n",
        "            }, indent=2)\n",
        "\n",
        "        hotels = []\n",
        "        for p in properties:\n",
        "            name = p.get(\"name\") or p.get(\"title\") or \"Unknown\"\n",
        "\n",
        "            # Rating - according to API docs, it's \"overall_rating\"\n",
        "            rating = p.get(\"overall_rating\") or p.get(\"rating\")\n",
        "\n",
        "            # Location/Area - according to API docs, location is an object\n",
        "            area = \"Unknown\"\n",
        "            location = p.get(\"location\")\n",
        "            if location:\n",
        "                if isinstance(location, dict):\n",
        "                    area = location.get(\"neighborhood\") or location.get(\"city\") or location.get(\"address\") or \"Unknown\"\n",
        "                elif isinstance(location, str):\n",
        "                    area = location\n",
        "            else:\n",
        "                # Fallback to direct fields\n",
        "                area = p.get(\"neighborhood\") or p.get(\"address\") or \"Unknown\"\n",
        "\n",
        "            # Price extraction - according to API docs:\n",
        "            # rate_per_night.extracted_lowest or total_rate.extracted_lowest\n",
        "            price_per_night = None\n",
        "            \n",
        "            # Try rate_per_night.extracted_lowest first (per API docs)\n",
        "            rate_per_night = p.get(\"rate_per_night\")\n",
        "            if rate_per_night and isinstance(rate_per_night, dict):\n",
        "                price_per_night = rate_per_night.get(\"extracted_lowest\")\n",
        "            \n",
        "            # Fallback to total_rate.extracted_lowest\n",
        "            if price_per_night is None:\n",
        "                total_rate = p.get(\"total_rate\")\n",
        "                if total_rate and isinstance(total_rate, dict):\n",
        "                    price_per_night = total_rate.get(\"extracted_lowest\")\n",
        "            \n",
        "            # Additional fallbacks for compatibility\n",
        "            if price_per_night is None:\n",
        "                raw_price = p.get(\"rate\") or p.get(\"price\")\n",
        "                if isinstance(raw_price, (int, float)):\n",
        "                    price_per_night = float(raw_price)\n",
        "                elif isinstance(raw_price, dict):\n",
        "                    price_per_night = raw_price.get(\"extracted_lowest\") or raw_price.get(\"rate\") or raw_price.get(\"price\")\n",
        "                    if price_per_night:\n",
        "                        try:\n",
        "                            price_per_night = float(price_per_night)\n",
        "                        except (ValueError, TypeError):\n",
        "                            price_per_night = None\n",
        "                elif isinstance(raw_price, str):\n",
        "                    # Extract number from string like \"$120/night\" or \"120\"\n",
        "                    import re\n",
        "                    numbers = re.findall(r'\\d+\\.?\\d*', raw_price.replace(',', ''))\n",
        "                    if numbers:\n",
        "                        try:\n",
        "                            price_per_night = float(numbers[0])\n",
        "                        except (ValueError, TypeError):\n",
        "                            price_per_night = None\n",
        "            \n",
        "            # Skip hotels without valid price or rating\n",
        "            if price_per_night is None:\n",
        "                continue\n",
        "            \n",
        "            # Convert rating to float for filtering\n",
        "            try:\n",
        "                rating_float = float(rating) if rating is not None else 0.0\n",
        "            except (ValueError, TypeError):\n",
        "                rating_float = 0.0\n",
        "            \n",
        "            # Apply min_rating filter\n",
        "            if rating_float < min_rating:\n",
        "                continue\n",
        "            \n",
        "            # Apply max_price filter\n",
        "            if max_price is not None and price_per_night > max_price:\n",
        "                continue\n",
        "\n",
        "            hotels.append({\n",
        "                \"name\": name,\n",
        "                \"rating\": rating_float,\n",
        "                \"area\": area or \"Unknown\",\n",
        "                \"price_per_night\": price_per_night,  # ✅ Fixed: use price_per_night not raw_price_field\n",
        "            })\n",
        "\n",
        "        # Return top 5 hotels\n",
        "        return json.dumps(hotels[:5], indent=2)\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca745c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# SECTION 3: HELPER FUNCTIONS\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def normalize_weights(w_dict, dims):\n",
        "    total = sum(w_dict[d] for d in dims)\n",
        "    if total == 0:\n",
        "        return {d: 1.0 / len(dims) for d in dims}\n",
        "    return {d: w_dict[d] / total for d in dims}\n",
        "\n",
        "\n",
        "def find_most_common_window(group_members):\n",
        "    \"\"\"\n",
        "    Find the most common two-day window from all group members' preferred windows.\n",
        "    \n",
        "    Args:\n",
        "        group_members: List of member dicts, each with a \"preferred_windows\" list\n",
        "                      containing dicts with \"trip_start\" and \"trip_end\" dates\n",
        "    \n",
        "    Returns:\n",
        "        dict with \"trip_start\" and \"trip_end\" of the most common window,\n",
        "        or None if no windows found\n",
        "    \"\"\"\n",
        "    from collections import Counter\n",
        "    \n",
        "    # Collect all preferred windows from all members\n",
        "    window_counts = Counter()\n",
        "    \n",
        "    for member in group_members:\n",
        "        preferred_windows = member.get(\"preferred_windows\", [])\n",
        "        for window in preferred_windows:\n",
        "            # Create a tuple key from the dates for counting\n",
        "            window_key = (window.get(\"trip_start\"), window.get(\"trip_end\"))\n",
        "            if window_key[0] and window_key[1]:  # Ensure both dates exist\n",
        "                window_counts[window_key] += 1\n",
        "    \n",
        "    if not window_counts:\n",
        "        return None\n",
        "    \n",
        "    # Find the most common window\n",
        "    most_common = window_counts.most_common(1)[0]\n",
        "    trip_start, trip_end = most_common[0]\n",
        "    count = most_common[1]\n",
        "    \n",
        "    return {\n",
        "        \"trip_start\": trip_start,\n",
        "        \"trip_end\": trip_end,\n",
        "        \"member_count\": count,  # How many members prefer this window\n",
        "        \"total_members\": len(group_members)\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_fairness_summary(group_members):\n",
        "    \"\"\"\n",
        "    Calculate fairness score based on budget ratios.\n",
        "    Each member dict must have: name, total_budget, flight_price, hotel_share, activities_spend\n",
        "    \"\"\"\n",
        "    def affordability_component(mean_ratio):\n",
        "        if mean_ratio <= 0.6:\n",
        "            return 1.0\n",
        "        if mean_ratio >= 1.4:\n",
        "            return 0.0\n",
        "        return 1.0 - (mean_ratio - 0.6) / (1.4 - 0.6)\n",
        "\n",
        "    def equality_component(std_ratio):\n",
        "        if std_ratio <= 0.05:\n",
        "            return 1.0\n",
        "        if std_ratio >= 0.25:\n",
        "            return 0.0\n",
        "        return 1.0 - (std_ratio - 0.05) / (0.25 - 0.05)\n",
        "\n",
        "    def affordability_label(r):\n",
        "        if r <= 0.6:\n",
        "            return \"comfortable\"\n",
        "        elif r <= 1.0:\n",
        "            return \"stretch\"\n",
        "        elif r <= 1.3:\n",
        "            return \"risky\"\n",
        "        else:\n",
        "            return \"not_recommended\"\n",
        "\n",
        "    ratios = []\n",
        "    per_person = []\n",
        "\n",
        "    for p in group_members:\n",
        "        trip_cost = p[\"flight_price\"] + p[\"hotel_share\"] + p[\"activities_spend\"]\n",
        "        r = trip_cost / p[\"total_budget\"]\n",
        "        label = affordability_label(r)\n",
        "\n",
        "        per_person.append({\n",
        "            \"name\": p[\"name\"],\n",
        "            \"trip_cost\": round(trip_cost, 2),\n",
        "            \"budget\": p[\"total_budget\"],\n",
        "            \"affordability_ratio\": round(r, 3),\n",
        "            \"affordability_label\": label,\n",
        "        })\n",
        "        ratios.append(min(r, 2.0))\n",
        "\n",
        "    ratios = np.array(ratios, dtype=float)\n",
        "    mean_ratio = float(ratios.mean())\n",
        "    std_ratio = float(ratios.std())\n",
        "\n",
        "    aff_comp = affordability_component(mean_ratio)\n",
        "    eq_comp = equality_component(std_ratio)\n",
        "\n",
        "    fairness_score = 100 * (0.6 * aff_comp + 0.4 * eq_comp)\n",
        "    fairness_score = max(0.0, min(100.0, fairness_score))\n",
        "\n",
        "    return {\n",
        "        \"trip_fairness_score\": round(fairness_score, 1),\n",
        "        \"mean_ratio\": round(mean_ratio, 3),\n",
        "        \"std_ratio\": round(std_ratio, 3),\n",
        "        \"per_person\": per_person,\n",
        "    }\n",
        "\n",
        "\n",
        "# Load activities dataframe and define constants\n",
        "activities_df = pd.read_csv(\"activities.csv\")\n",
        "DIMS = [\"nightlife\", \"adventure\", \"shopping\", \"food\", \"urban\"]\n",
        "TAG_COLS = [f\"tag_{d}\" for d in DIMS]\n",
        "\n",
        "\n",
        "def compute_base_scores_for_city(\n",
        "    city: str,\n",
        "    group_members: List[Dict[str, Any]],\n",
        "    top_k_activities: int = 10,\n",
        "    min_stars: float = 3.5,\n",
        "    min_review_count: int = 30,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Filter activities for the city, compute base enjoyment/value scores per user and per activity,\n",
        "    and return the top K activities by group value.\n",
        "    \"\"\"\n",
        "    # 1) Normalize user preference weights\n",
        "    for m in group_members:\n",
        "        m[\"norm_weights\"] = normalize_weights(m[\"preference_weights\"], DIMS)\n",
        "\n",
        "    # 2) Filter activities for the chosen city & quality\n",
        "    city_df = activities_df[\n",
        "        (activities_df[\"city\"] == city)\n",
        "        & (activities_df[\"stars\"] >= min_stars)\n",
        "        & (activities_df[\"review_count\"] >= min_review_count)\n",
        "    ].copy()\n",
        "\n",
        "    if city_df.empty:\n",
        "        raise ValueError(f\"No activities found for city={city} with current filters.\")\n",
        "\n",
        "    # Ensure price_proxy exists; if not, create from price_level\n",
        "    if \"price_proxy\" not in city_df.columns:\n",
        "        price_map = {1: 15, 2: 30, 3: 50, 4: 80}\n",
        "        city_df[\"price_proxy\"] = city_df[\"price_level\"].map(price_map)\n",
        "\n",
        "    # 3) Compute base enjoyment + value per user and group\n",
        "    group_values = []\n",
        "    per_user_scores: Dict[str, Dict[str, float]] = {\n",
        "        m[\"id\"]: {} for m in group_members\n",
        "    }  # user_id -> {business_id: value_score}\n",
        "\n",
        "    for idx, row in city_df.iterrows():\n",
        "        biz_id = row[\"business_id\"]\n",
        "        tags_vec = np.array([row[col] for col in TAG_COLS], dtype=float)\n",
        "        price = float(row[\"price_proxy\"]) if not pd.isna(row[\"price_proxy\"]) else 1.0\n",
        "\n",
        "        user_values = []\n",
        "        for m in group_members:\n",
        "            w_vec = np.array([m[\"norm_weights\"][d] for d in DIMS], dtype=float)\n",
        "            base_enjoyment = float((w_vec * tags_vec).sum())\n",
        "            value_score = base_enjoyment / max(price, 1e-6)\n",
        "            per_user_scores[m[\"id\"]][biz_id] = value_score\n",
        "            user_values.append(value_score)\n",
        "\n",
        "        group_value = float(np.mean(user_values))\n",
        "        group_values.append((biz_id, group_value))\n",
        "\n",
        "    # 4) Select top K activities by group value\n",
        "    group_values_sorted = sorted(group_values, key=lambda x: x[1], reverse=True)\n",
        "    top_biz_ids = [biz_id for biz_id, _ in group_values_sorted[:top_k_activities]]\n",
        "\n",
        "    top_city_df = city_df[city_df[\"business_id\"].isin(top_biz_ids)].copy()\n",
        "\n",
        "    return {\n",
        "        \"city_df\": top_city_df,\n",
        "        \"per_user_scores\": per_user_scores,\n",
        "        \"top_biz_ids\": top_biz_ids,\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_json_from_markdown(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract JSON from markdown code blocks.\n",
        "    Handles cases where LLM wraps JSON in ```json ... ``` or ``` ... ```\n",
        "    \"\"\"\n",
        "    content = text.strip()\n",
        "    \n",
        "    # Remove markdown code block markers if present\n",
        "    if content.startswith(\"```json\"):\n",
        "        content = content[7:]  # Remove ```json\n",
        "    elif content.startswith(\"```\"):\n",
        "        content = content[3:]   # Remove ```\n",
        "    \n",
        "    if content.endswith(\"```\"):\n",
        "        content = content[:-3]   # Remove closing ```\n",
        "    \n",
        "    return content.strip()\n",
        "\n",
        "\n",
        "def build_llm_for_reranking(temperature: float = 0.3) -> ChatGoogleGenerativeAI:\n",
        "    \"\"\"Create a Gemini LLM instance for reranking.\"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash-lite\",\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "\n",
        "def rerank_with_gemini(\n",
        "    city: str,\n",
        "    group_members: List[Dict[str, Any]],\n",
        "    base_info: Dict[str, Any],\n",
        "    llm: ChatGoogleGenerativeAI,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    For each user and each of the top activities, call Gemini to get:\n",
        "      - adjusted_enjoyment_score\n",
        "      - recommended_time_of_day\n",
        "      - note\n",
        "\n",
        "    Returns a list of dicts: one entry per (user, activity).\n",
        "    \"\"\"\n",
        "    city_df = base_info[\"city_df\"]\n",
        "    per_user_scores = base_info[\"per_user_scores\"]\n",
        "    top_biz_ids = base_info[\"top_biz_ids\"]\n",
        "\n",
        "    # We'll process per-user, sending all top activities in one call per user\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for m in group_members:\n",
        "        # Handle missing total_budget gracefully (use default or get from budget field)\n",
        "        total_budget = m.get(\"total_budget\") or m.get(\"budget\")\n",
        "        if total_budget is None:\n",
        "            raise ValueError(f\"Missing 'total_budget' field for user {m.get('id', 'unknown')}. Each group member must have a 'total_budget' field.\")\n",
        "        \n",
        "        user_profile = {\n",
        "            \"id\": m[\"id\"],\n",
        "            \"name\": m[\"name\"],\n",
        "            \"total_budget\": total_budget,\n",
        "            \"norm_weights\": m[\"norm_weights\"],\n",
        "            \"notes\": m.get(\"notes\", \"\"),\n",
        "        }\n",
        "\n",
        "        # Build concise activity list\n",
        "        # Limit to 15 activities per call to avoid output truncation (8K token limit)\n",
        "        MAX_ACTIVITIES_PER_CALL = 15\n",
        "        activities_payload = []\n",
        "        for idx, (_, row) in enumerate(city_df.iterrows()):\n",
        "            if idx >= MAX_ACTIVITIES_PER_CALL:\n",
        "                break\n",
        "            biz_id = row[\"business_id\"]\n",
        "            activities_payload.append({\n",
        "                \"business_id\": biz_id,\n",
        "                \"name\": row[\"name\"],\n",
        "                \"stars\": float(row[\"stars\"]),\n",
        "                \"review_count\": int(row[\"review_count\"]),\n",
        "                \"price_proxy\": float(row[\"price_proxy\"]),\n",
        "                \"value_score\": per_user_scores[m[\"id\"]].get(biz_id, 0.0),\n",
        "                \"tags5\": {\n",
        "                    d: float(row[f\"tag_{d}\"]) for d in DIMS\n",
        "                },\n",
        "            })\n",
        "\n",
        "        # Prepare prompt\n",
        "        system_instructions = \"\"\"\n",
        "You are a trip personalization model.\n",
        "You receive a single user's profile and a list of candidate activities in one city.\n",
        "\n",
        "For each activity, you must produce:\n",
        "- adjusted_enjoyment_score (0–10, float)\n",
        "- recommended_time_of_day (\"morning\" | \"afternoon\" | \"evening\" | \"late night\")\n",
        "- note: MAX 15 words explaining why this user would or would not like it.\n",
        "\n",
        "Consider:\n",
        "- The user's normalized weights per dimension (nightlife, adventure, shopping, food, urban).\n",
        "- The user's free-text notes.\n",
        "- The activity's tag scores, rating, review_count, and price_proxy.\n",
        "- The base value_score as a hint, but you can override it.\n",
        "\n",
        "CRITICAL REQUIREMENTS:\n",
        "1. Return ONLY raw JSON (no markdown code blocks, no ```json, no explanations, no extra text)\n",
        "2. Keep \"note\" fields to MAX 15 words each\n",
        "3. Return the complete JSON object - do not truncate\n",
        "4. Start your response with { and end with }\n",
        "\n",
        "Return valid JSON in this exact format:\n",
        "{\n",
        "  \"user_id\": \"...\",\n",
        "  \"city\": \"...\",\n",
        "  \"results\": [\n",
        "    {\n",
        "      \"business_id\": \"...\",\n",
        "      \"adjusted_enjoyment_score\": 0.0,\n",
        "      \"recommended_time_of_day\": \"evening\",\n",
        "      \"note\": \"Short 15-word max note here\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "        user_payload = {\n",
        "            \"user_profile\": user_profile,\n",
        "            \"city\": city,\n",
        "            \"activities\": activities_payload,\n",
        "        }\n",
        "\n",
        "        prompt = system_instructions.strip() + \"\\n\\nUser + activities JSON:\\n\" + json.dumps(\n",
        "            user_payload, indent=2\n",
        "        )\n",
        "\n",
        "        response = llm.invoke(prompt)\n",
        "        \n",
        "        # Extract JSON from response (handle markdown code blocks)\n",
        "        content = extract_json_from_markdown(response.content)\n",
        "        \n",
        "        # Check for truncation (incomplete JSON)\n",
        "        content_stripped = content.strip()\n",
        "        if not content_stripped.endswith(\"}\"):\n",
        "            print(f\"⚠️ WARNING: Response may be truncated for user {m['id']}\")\n",
        "            print(f\"Response ends with: ...{content_stripped[-50:]}\")\n",
        "            # Try to extract partial results if possible\n",
        "            # Look for the last complete result entry\n",
        "        \n",
        "        try:\n",
        "            parsed = json.loads(content)\n",
        "        except json.JSONDecodeError as e:\n",
        "            # Fallback: skip this user if parsing fails\n",
        "            print(f\"❌ JSON parsing failed for user {m['id']}: {str(e)}\")\n",
        "            print(f\"Response preview: {response.content[:300]}\")\n",
        "            print(f\"Extracted content preview: {content[:300]}\")\n",
        "            continue\n",
        "\n",
        "        # Append per-activity results, but enforce schema\n",
        "        for item in parsed.get(\"results\", []):\n",
        "            results.append({\n",
        "                \"user_id\": parsed.get(\"user_id\", m[\"id\"]),\n",
        "                \"city\": parsed.get(\"city\", city),\n",
        "                \"business_id\": item[\"business_id\"],\n",
        "                \"adjusted_enjoyment_score\": float(item[\"adjusted_enjoyment_score\"]),\n",
        "                \"recommended_time_of_day\": item[\"recommended_time_of_day\"],\n",
        "                \"note\": item[\"note\"],\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def find_and_rerank_activities_tool(input_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Input JSON:\n",
        "    {\n",
        "      \"city\": \"New Orleans\",\n",
        "      \"group_members\": [\n",
        "        {\n",
        "          \"id\": \"u1\",\n",
        "          \"name\": \"Alice\",\n",
        "          \"total_budget\": 900,\n",
        "          \"preference_weights\": {...},\n",
        "          \"notes\": \"...\"\n",
        "        },\n",
        "        ...\n",
        "      ],\n",
        "      \"top_k\": 10   # optional\n",
        "    }\n",
        "\n",
        "    Output JSON:\n",
        "    {\n",
        "      \"city\": \"New Orleans\",\n",
        "      \"activities\": [\n",
        "        {\n",
        "          \"user_id\": \"u1\",\n",
        "          \"business_id\": \"abc123\",\n",
        "          \"adjusted_enjoyment_score\": 8.8,\n",
        "          \"recommended_time_of_day\": \"evening\",\n",
        "          \"note\": \"Great for nightlife lovers...\"\n",
        "        },\n",
        "        ...\n",
        "      ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    data = json.loads(input_json)\n",
        "    city = data[\"city\"]\n",
        "    group_members = data[\"group_members\"]\n",
        "    top_k = data.get(\"top_k\", 5)\n",
        "\n",
        "    # Validate required fields in group_members\n",
        "    required_fields = [\"id\", \"name\", \"total_budget\", \"preference_weights\"]\n",
        "    for i, member in enumerate(group_members):\n",
        "        missing = [field for field in required_fields if field not in member]\n",
        "        if missing:\n",
        "            return json.dumps({\n",
        "                \"error\": f\"Missing required fields for group_members[{i}]: {missing}. Each member must have: id, name, total_budget, preference_weights\"\n",
        "            })\n",
        "\n",
        "    # 1) Compute base scores & pick top K activities\n",
        "    base_info = compute_base_scores_for_city(city, group_members, top_k_activities=top_k)\n",
        "\n",
        "    # 2) LLM rerank/enrich for each user-activity pair\n",
        "    llm = build_llm_for_reranking()\n",
        "    reranked = rerank_with_gemini(city, group_members, base_info, llm)\n",
        "\n",
        "    # 3) Limit and optimize output to prevent overwhelming the agent\n",
        "    # Group activities by user and keep only top 10 per user\n",
        "    MAX_ACTIVITIES_PER_USER = 10\n",
        "    activities_by_user = {}\n",
        "    for activity in reranked:\n",
        "        user_id = activity[\"user_id\"]\n",
        "        if user_id not in activities_by_user:\n",
        "            activities_by_user[user_id] = []\n",
        "        activities_by_user[user_id].append(activity)\n",
        "    \n",
        "    # Sort by score and keep top N per user\n",
        "    limited_activities = []\n",
        "    for user_id, user_activities in activities_by_user.items():\n",
        "        sorted_activities = sorted(\n",
        "            user_activities, \n",
        "            key=lambda x: x[\"adjusted_enjoyment_score\"], \n",
        "            reverse=True\n",
        "        )\n",
        "        limited_activities.extend(sorted_activities[:MAX_ACTIVITIES_PER_USER])\n",
        "    \n",
        "    # Build compact output with summary\n",
        "    # Calculate summary stats\n",
        "    if limited_activities:\n",
        "        scores = [a[\"adjusted_enjoyment_score\"] for a in limited_activities]\n",
        "        time_dist = {}\n",
        "        for a in limited_activities:\n",
        "            time = a[\"recommended_time_of_day\"]\n",
        "            time_dist[time] = time_dist.get(time, 0) + 1\n",
        "    else:\n",
        "        scores = []\n",
        "        time_dist = {}\n",
        "    \n",
        "    output = {\n",
        "        \"city\": city,\n",
        "        \"summary\": {\n",
        "            \"total_activities\": len(limited_activities),\n",
        "            \"score_range\": [min(scores), max(scores)] if scores else [0, 0],\n",
        "            \"time_distribution\": time_dist\n",
        "        },\n",
        "        \"activities\": limited_activities[:20],  # Hard limit: max 20 activities total\n",
        "    }\n",
        "    return json.dumps(output)  # No indent to reduce size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "ea151ab9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# SECTION 4: LANGCHAIN TOOL DEFINITIONS\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "@tool\n",
        "def choose_city_tool(group_profile_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Choose the best city for the group based on preferences + budgets.\n",
        "    Input: JSON with {group_members: [...]}\n",
        "    Output: JSON with {\"best_city\": \"...\", \"city_scores\": [...], \"explanation\": \"...\"}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define constants (in case they're not in global scope)\n",
        "        DIMS = [\"nightlife\", \"adventure\", \"shopping\", \"food\", \"urban\"]\n",
        "        \n",
        "        group_profile = json.loads(group_profile_json)\n",
        "        group_members = group_profile.get(\"group_members\", [])\n",
        "        \n",
        "        if not group_members:\n",
        "            return json.dumps({\"error\": \"No group members provided\"})\n",
        "        \n",
        "        # 1. Normalize preference weights for each member\n",
        "        for m in group_members:\n",
        "            m[\"norm_weights\"] = normalize_weights(m[\"preference_weights\"], DIMS)\n",
        "        \n",
        "        # 2. Compute group-level average preferences\n",
        "        group_weights = {\n",
        "            d: float(np.mean([m[\"norm_weights\"][d] for m in group_members]))\n",
        "            for d in DIMS\n",
        "        }\n",
        "        \n",
        "        # 3. Load activities and compute city stats\n",
        "        # Always load from CSV to avoid scope issues\n",
        "        activities_df_local = pd.read_csv(\"activities.csv\")\n",
        "        \n",
        "        # Compute city-level vibes & costs\n",
        "        tag_cols = [f\"tag_{d}\" for d in DIMS]\n",
        "        price_map = {1: 15, 2: 30, 3: 50, 4: 80}\n",
        "        activities_df_local[\"price_proxy\"] = activities_df_local[\"price_level\"].map(price_map)\n",
        "        \n",
        "        city_stats = (\n",
        "            activities_df_local\n",
        "            .groupby(\"city\")\n",
        "            .agg(\n",
        "                avg_tag_nightlife=(\"tag_nightlife\", \"mean\"),\n",
        "                avg_tag_adventure=(\"tag_adventure\", \"mean\"),\n",
        "                avg_tag_shopping=(\"tag_shopping\", \"mean\"),\n",
        "                avg_tag_food=(\"tag_food\", \"mean\"),\n",
        "                avg_tag_urban=(\"tag_urban\", \"mean\"),\n",
        "                avg_price_proxy=(\"price_proxy\", \"mean\"),\n",
        "                n_places=(\"business_id\", \"nunique\"),\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "        \n",
        "        # Filter cities with enough places\n",
        "        city_stats = city_stats[city_stats[\"n_places\"] >= 20].copy()\n",
        "        \n",
        "        # Build vibe vectors\n",
        "        for d in DIMS:\n",
        "            city_stats[f\"vibe_{d}\"] = city_stats[f\"avg_tag_{d}\"]\n",
        "        \n",
        "        # Normalize vibes per city\n",
        "        vibe_cols = [f\"vibe_{d}\" for d in DIMS]\n",
        "        city_stats[\"vibe_sum\"] = city_stats[vibe_cols].sum(axis=1)\n",
        "        city_stats[vibe_cols] = city_stats[vibe_cols].div(city_stats[\"vibe_sum\"], axis=0)\n",
        "        city_stats.drop(columns=[\"vibe_sum\"], inplace=True)\n",
        "        \n",
        "        # Compute cost_index (0-1 scale)\n",
        "        min_cost = city_stats[\"avg_price_proxy\"].min()\n",
        "        max_cost = city_stats[\"avg_price_proxy\"].max()\n",
        "        city_stats[\"cost_index\"] = (city_stats[\"avg_price_proxy\"] - min_cost) / (max_cost - min_cost + 1e-9)\n",
        "        \n",
        "        def cost_level(x):\n",
        "            if x < 0.33:\n",
        "                return \"low\"\n",
        "            elif x < 0.66:\n",
        "                return \"medium\"\n",
        "            else:\n",
        "                return \"high\"\n",
        "        \n",
        "        city_stats[\"typical_cost_level\"] = city_stats[\"cost_index\"].apply(cost_level)\n",
        "        \n",
        "        # 4. Score each city using your algorithm\n",
        "        def score_city_row(row, group_weights, lambda_cost=0.6):\n",
        "            city_vec = np.array([row[f\"vibe_{d}\"] for d in DIMS], dtype=float)\n",
        "            w_vec = np.array([group_weights[d] for d in DIMS], dtype=float)\n",
        "            \n",
        "            vibe_score = float((city_vec * w_vec).sum())\n",
        "            cost_index = float(row[\"cost_index\"])\n",
        "            \n",
        "            # Penalize expensive cities\n",
        "            cost_penalty = 1.0 / (1.0 + lambda_cost * cost_index)\n",
        "            combined_score = vibe_score * cost_penalty\n",
        "            \n",
        "            return vibe_score, combined_score\n",
        "        \n",
        "        city_scores = []\n",
        "        for _, row in city_stats.iterrows():\n",
        "            vibe, combined = score_city_row(row, group_weights)\n",
        "            city_scores.append({\n",
        "                \"city\": row[\"city\"],\n",
        "                \"vibe_score\": vibe,\n",
        "                \"combined_score\": combined,\n",
        "                \"avg_price_proxy\": float(row[\"avg_price_proxy\"]),\n",
        "                \"cost_index\": float(row[\"cost_index\"]),\n",
        "                \"typical_cost_level\": row[\"typical_cost_level\"],\n",
        "                \"n_places\": int(row[\"n_places\"]),\n",
        "                \"vibe_tags\": {d: float(row[f\"vibe_{d}\"]) for d in DIMS},\n",
        "            })\n",
        "        \n",
        "        # 5. Sort by combined_score and get best city\n",
        "        city_scores_sorted = sorted(city_scores, key=lambda x: x[\"combined_score\"], reverse=True)\n",
        "        best_city = city_scores_sorted[0]\n",
        "        \n",
        "        # 6. Build result\n",
        "        result = {\n",
        "            \"best_city\": best_city[\"city\"],\n",
        "            \"city_scores\": city_scores_sorted[:10],  # Top 10 cities\n",
        "            \"explanation\": f\"{best_city['city']} has the highest combined score ({best_city['combined_score']:.3f}) based on group preferences and cost.\"\n",
        "        }\n",
        "        \n",
        "        return json.dumps(result, indent=2)\n",
        "        \n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return json.dumps({\"error\": str(e), \"traceback\": traceback.format_exc()})\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_flights_tool(\n",
        "    origin: str,\n",
        "    destination: str,\n",
        "    depart_date: str,\n",
        "    return_date: str,\n",
        "    max_price: Optional[float] = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Search flights between origin and destination using SerpAPI.\n",
        "    Takes city names and converts them to airport codes.\n",
        "    Returns JSON list: [{price, airline, depart_time, arrive_time, legs}, ...]\n",
        "    \"\"\"\n",
        "    import requests\n",
        "    import os\n",
        "    \n",
        "    # City to airport code mapping for the 5 destination cities\n",
        "    CITY_TO_AIRPORT = {\n",
        "        \"Philadelphia\": \"PHL\",\n",
        "        \"Tucson\": \"TUS\",\n",
        "        \"Tampa\": \"TPA\",\n",
        "        \"Boise\": \"BOI\",\n",
        "        \"New Orleans\": \"MSY\",\n",
        "    }\n",
        "    \n",
        "    # Common origin city airports (add more as needed)\n",
        "    ORIGIN_AIRPORTS = {\n",
        "        \"Chicago\": \"ORD\",  # O'Hare\n",
        "        \"New York\": \"JFK\",\n",
        "        \"Los Angeles\": \"LAX\",\n",
        "        \"San Francisco\": \"SFO\",\n",
        "        \"Boston\": \"BOS\",\n",
        "        \"Atlanta\": \"ATL\",\n",
        "        \"Dallas\": \"DFW\",\n",
        "        \"Seattle\": \"SEA\",\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # Convert city names to airport codes\n",
        "        origin_code = ORIGIN_AIRPORTS.get(origin, origin.upper()[:3])  # Default to first 3 chars if not found\n",
        "        dest_code = CITY_TO_AIRPORT.get(destination, destination.upper()[:3])\n",
        "        \n",
        "        # If already airport codes, use them directly\n",
        "        if len(origin) == 3 and origin.isupper():\n",
        "            origin_code = origin\n",
        "        if len(destination) == 3 and destination.isupper():\n",
        "            dest_code = destination\n",
        "        \n",
        "        # Normalize to uppercase\n",
        "        origin_code = origin_code.strip().upper()\n",
        "        dest_code = dest_code.strip().upper()\n",
        "        \n",
        "        SERPAPI_KEY = os.getenv('SERPAPI_KEY')\n",
        "        \n",
        "        if not SERPAPI_KEY:\n",
        "            return json.dumps({\"error\": \"SERPAPI_KEY not found in environment variables. Please set SERPAPI_KEY.\"})\n",
        "        \n",
        "        # API call\n",
        "        params = {\n",
        "            \"engine\": \"google_flights\",\n",
        "            \"departure_id\": origin_code,\n",
        "            \"arrival_id\": dest_code,\n",
        "            \"outbound_date\": depart_date,\n",
        "            \"return_date\": return_date,\n",
        "            \"currency\": \"USD\",\n",
        "            \"hl\": \"en\",\n",
        "            \"api_key\": SERPAPI_KEY\n",
        "        }\n",
        "        \n",
        "        response = requests.get(\"https://serpapi.com/search.json\", params=params, timeout=30)\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            return json.dumps({\"error\": f\"API Error: {response.status_code}\"})\n",
        "        \n",
        "        data = response.json()\n",
        "        \n",
        "        if \"error\" in data:\n",
        "            return json.dumps({\"error\": data[\"error\"]})\n",
        "        \n",
        "        # Get all flights\n",
        "        all_flights = data.get(\"best_flights\", []) + data.get(\"other_flights\", [])\n",
        "        \n",
        "        if not all_flights:\n",
        "            return json.dumps({\"error\": \"No flights found\"})\n",
        "        \n",
        "        # Sort by price, get top 3\n",
        "        cheapest = sorted(all_flights, key=lambda x: x.get('price', 999999))[:3]\n",
        "        \n",
        "        # Format results to match expected format\n",
        "        results = []\n",
        "        for flight in cheapest:\n",
        "            legs = flight.get(\"flights\", [])\n",
        "            if not legs:\n",
        "                continue\n",
        "            \n",
        "            # Extract times\n",
        "            depart_time = legs[0].get(\"departure_airport\", {}).get(\"time\", \"\")\n",
        "            arrive_time = legs[-1].get(\"arrival_airport\", {}).get(\"time\", \"\")\n",
        "            \n",
        "            # Format times to match expected format (YYYY-MM-DDTHH:MM)\n",
        "            if depart_time and \"T\" not in depart_time:\n",
        "                depart_time = f\"{depart_date}T{depart_time}\"\n",
        "            if arrive_time and \"T\" not in arrive_time:\n",
        "                arrive_time = f\"{return_date}T{arrive_time}\"\n",
        "            \n",
        "            results.append({\n",
        "                \"price\": flight.get(\"price\"),\n",
        "                \"airline\": legs[0].get(\"airline\", \"Unknown\"),\n",
        "                \"depart_time\": depart_time,\n",
        "                \"arrive_time\": arrive_time,\n",
        "                \"legs\": len(legs),\n",
        "            })\n",
        "        \n",
        "        # Filter by max_price if provided\n",
        "        if max_price is not None:\n",
        "            results = [f for f in results if f.get(\"price\", 999999) <= max_price]\n",
        "        \n",
        "        return json.dumps(results)\n",
        "    \n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "'''@tool\n",
        "def search_hotels_tool(\n",
        "    city: str,\n",
        "    checkin: str,\n",
        "    checkout: str,\n",
        "    max_price: Optional[float] = None,\n",
        "    min_rating: float = 3.0,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Search hotels in a city for given dates.\n",
        "    Returns JSON list: [{price_per_night, name, rating, area}, ...]\n",
        "    \"\"\"\n",
        "    try:\n",
        "        hotels = search_hotels(city, checkin, checkout, max_price=max_price, min_rating=min_rating)\n",
        "        return json.dumps(hotels)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})'''\n",
        "\n",
        "@tool\n",
        "def search_hotels_tool(\n",
        "    city: str,\n",
        "    checkin: str,\n",
        "    checkout: str,\n",
        "    max_price: Optional[float] = None,\n",
        "    min_rating: float = 0.0,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Minimal Google Hotels search via SerpAPI.\n",
        "    \n",
        "    Inputs:\n",
        "      - city: e.g. \"New Orleans\"\n",
        "      - checkin: \"YYYY-MM-DD\"\n",
        "      - checkout: \"YYYY-MM-DD\"\n",
        "      - max_price: optional upper bound in USD (not applied in this minimal version)\n",
        "      - min_rating: minimum rating (not strictly applied here – we mostly just expose fields)\n",
        "    \n",
        "    Returns:\n",
        "      JSON list of up to 5 hotels (filtered by max_price and min_rating):\n",
        "        [\n",
        "          {\n",
        "            \"name\": \"Hotel Name\",\n",
        "            \"rating\": 4.5,\n",
        "            \"area\": \"Downtown\",\n",
        "            \"price_per_night\": 120,\n",
        "          },\n",
        "          ...\n",
        "        ]\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
        "        if not SERPAPI_KEY:\n",
        "            return json.dumps({\n",
        "                \"error\": \"SERPAPI_KEY not found in environment variables. Please set SERPAPI_KEY.\"\n",
        "            })\n",
        "\n",
        "        params = {\n",
        "            \"engine\": \"google_hotels\",\n",
        "            \"q\": city,\n",
        "            \"check_in_date\": checkin,\n",
        "            \"check_out_date\": checkout,\n",
        "            \"adults\": 2,\n",
        "            \"currency\": \"USD\",\n",
        "            \"hl\": \"en\",\n",
        "            \"gl\": \"us\",\n",
        "            \"api_key\": SERPAPI_KEY,\n",
        "        }\n",
        "\n",
        "        resp = requests.get(\"https://serpapi.com/search.json\", params=params, timeout=30)\n",
        "        if resp.status_code != 200:\n",
        "            return json.dumps({\"error\": f\"API Error: {resp.status_code}\", \"details\": resp.text[:500]})\n",
        "\n",
        "        data = resp.json()\n",
        "\n",
        "        # Debug: if you want to see the keys:\n",
        "        # return json.dumps({\"top_level_keys\": list(data.keys())}, indent=2)\n",
        "\n",
        "        # Hotels are often under \"properties\" or \"results\" / \"hotel_results\"\n",
        "        properties = data.get(\"properties\") or data.get(\"hotel_results\") or data.get(\"results\") or []\n",
        "\n",
        "        if not properties:\n",
        "            # For debugging, you might want to temporarily return the whole payload shape:\n",
        "            return json.dumps({\n",
        "                \"error\": \"No hotels found in response under properties/hotel_results/results\",\n",
        "                \"top_level_keys\": list(data.keys()),\n",
        "            }, indent=2)\n",
        "\n",
        "        hotels = []\n",
        "        for p in properties:\n",
        "            name = p.get(\"name\") or p.get(\"title\") or \"Unknown\"\n",
        "\n",
        "            # Rating field varies; these are common:\n",
        "            rating = p.get(\"overall_rating\") or p.get(\"rating\")\n",
        "\n",
        "            # Neighborhood / area\n",
        "            area = p.get(\"neighborhood\")\n",
        "            if not area:\n",
        "                addr = p.get(\"address\") or p.get(\"location\")\n",
        "                if isinstance(addr, str):\n",
        "                    area = addr\n",
        "                elif isinstance(addr, dict):\n",
        "                    area = addr.get(\"neighborhood\") or addr.get(\"city\")\n",
        "\n",
        "            # Price extraction - extract numeric price_per_night\n",
        "            price_per_night = None\n",
        "            raw_price = p.get(\"rate\") or p.get(\"rate_per_night\") or p.get(\"prices\") or p.get(\"price\")\n",
        "            \n",
        "            if raw_price is not None:\n",
        "                if isinstance(raw_price, (int, float)):\n",
        "                    price_per_night = float(raw_price)\n",
        "                elif isinstance(raw_price, dict):\n",
        "                    # Try common price field names in dict\n",
        "                    price_per_night = raw_price.get(\"rate\") or raw_price.get(\"price\") or raw_price.get(\"amount\") or raw_price.get(\"value\")\n",
        "                    if price_per_night:\n",
        "                        try:\n",
        "                            price_per_night = float(price_per_night)\n",
        "                        except (ValueError, TypeError):\n",
        "                            price_per_night = None\n",
        "                elif isinstance(raw_price, str):\n",
        "                    # Extract number from string like \"$120/night\" or \"120\"\n",
        "                    import re\n",
        "                    numbers = re.findall(r'\\d+\\.?\\d*', raw_price.replace(',', ''))\n",
        "                    if numbers:\n",
        "                        try:\n",
        "                            price_per_night = float(numbers[0])\n",
        "                        except (ValueError, TypeError):\n",
        "                            price_per_night = None\n",
        "            \n",
        "            # Skip hotels without valid price or rating\n",
        "            if price_per_night is None:\n",
        "                continue\n",
        "            \n",
        "            # Convert rating to float for filtering\n",
        "            try:\n",
        "                rating_float = float(rating) if rating is not None else 0.0\n",
        "            except (ValueError, TypeError):\n",
        "                rating_float = 0.0\n",
        "            \n",
        "            # Apply min_rating filter\n",
        "            if rating_float < min_rating:\n",
        "                continue\n",
        "            \n",
        "            # Apply max_price filter\n",
        "            if max_price is not None and price_per_night > max_price:\n",
        "                continue\n",
        "\n",
        "            hotels.append({\n",
        "                \"name\": name,\n",
        "                \"rating\": rating_float,\n",
        "                \"area\": area or \"Unknown\",\n",
        "                \"price_per_night\": price_per_night,  \n",
        "            })\n",
        "\n",
        "        # Return top 5 hotels\n",
        "        return json.dumps(hotels[:5], indent=2)\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "@tool\n",
        "def score_activities_tool(input_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Score and rank activities for the chosen city.\n",
        "    Input: JSON {city, group_members, top_k}\n",
        "    Output: JSON {city, activities: [{user_id, business_id, adjusted_enjoyment_score, ...}]}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return find_and_rerank_activities_tool(input_json)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "@tool\n",
        "def fairness_tool(group_costs_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Compute fairness score from group costs.\n",
        "    Input: JSON {\"group_members\": [{name, total_budget, flight_price, hotel_share, activities_spend}, ...]}\n",
        "    Output: JSON {trip_fairness_score, mean_ratio, std_ratio, per_person: [...]}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(group_costs_json)\n",
        "        summary = compute_fairness_summary(data[\"group_members\"])\n",
        "        return json.dumps(summary)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "908fb69c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Testing search_hotels_tool()\n",
            "======================================================================\n",
            "\n",
            "1️⃣  Test 1: Basic hotel search\n",
            "----------------------------------------------------------------------\n",
            "⚠️  Found 0 hotels (empty list returned)\n",
            "   → This could mean:\n",
            "      - SERPAPI_KEY is not set or invalid\n",
            "      - API returned no hotels for these dates\n",
            "      - All hotels were filtered out by max_price/min_rating\n",
            "   → Check SERPAPI_KEY: os.getenv('SERPAPI_KEY')\n",
            "\n",
            "2️⃣  Test 2: With filters (max_price=200, min_rating=4.0)\n",
            "----------------------------------------------------------------------\n",
            "✅ Found 0 hotels (filtered)\n",
            "\n",
            "3️⃣  Test 3: Output format validation\n",
            "----------------------------------------------------------------------\n",
            "Expected format: List of dicts with 'name', 'rating', 'area', 'price_per_night'\n",
            "\n",
            "To test with real API:\n",
            "  1. Set SERPAPI_KEY: os.environ['SERPAPI_KEY'] = 'your_key'\n",
            "  2. Run: search_hotels_tool('Philadelphia', '2025-12-20', '2025-12-21')\n",
            "  3. Check that output has 'price_per_night' field (not 'raw_price_field')\n",
            "\n",
            "======================================================================\n",
            "Test complete!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# TEST CODE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"Testing search_hotels_tool()\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check if SERPAPI_KEY is set\n",
        "SERPAPI_KEY = os.getenv('SERPAPI_KEY')\n",
        "if not SERPAPI_KEY:\n",
        "    print(\"\\n⚠️  WARNING: SERPAPI_KEY not set!\")\n",
        "    print(\"   Set it with: os.environ['SERPAPI_KEY'] = 'your_key'\")\n",
        "    print(\"\\n   For testing without API, the function will return an error.\")\n",
        "    print(\"   Setting a dummy key for format testing...\")\n",
        "    os.environ['SERPAPI_KEY'] = 'test_key'  # Will fail API call but test format\n",
        "\n",
        "# Test 1: Basic call\n",
        "print(\"\\n1️⃣  Test 1: Basic hotel search\")\n",
        "print(\"-\"*70)\n",
        "try:\n",
        "    # Access the underlying function (bypass @tool wrapper)\n",
        "    if hasattr(search_hotels_tool, '__wrapped__'):\n",
        "        actual_func = search_hotels_tool.__wrapped__\n",
        "    else:\n",
        "        actual_func = search_hotels_tool\n",
        "    \n",
        "    result = actual_func(\n",
        "        city=\"New York\",\n",
        "        checkin=\"2025-12-20\",\n",
        "        checkout=\"2025-12-21\"\n",
        "    )\n",
        "    data = json.loads(result)\n",
        "    \n",
        "    # Check if result is an error\n",
        "    if isinstance(data, dict) and \"error\" in data:\n",
        "        print(f\"❌ Error: {data['error']}\")\n",
        "        if \"SERPAPI_KEY\" in data['error']:\n",
        "            print(\"   → This is expected if SERPAPI_KEY is not set or invalid\")\n",
        "        if \"top_level_keys\" in data:\n",
        "            print(f\"   → API response keys: {data['top_level_keys']}\")\n",
        "    elif isinstance(data, list):\n",
        "        if len(data) == 0:\n",
        "            print(f\"⚠️  Found 0 hotels (empty list returned)\")\n",
        "            print(\"   → This could mean:\")\n",
        "            print(\"      - SERPAPI_KEY is not set or invalid\")\n",
        "            print(\"      - API returned no hotels for these dates\")\n",
        "            print(\"      - All hotels were filtered out by max_price/min_rating\")\n",
        "            print(\"   → Check SERPAPI_KEY: os.getenv('SERPAPI_KEY')\")\n",
        "        else:\n",
        "            print(f\"✅ Success! Found {len(data)} hotels\")\n",
        "            print(\"\\nSample output:\")\n",
        "            if len(data) > 0:\n",
        "                print(json.dumps(data[0], indent=2))\n",
        "                print(\"\\n✅ Output format check:\")\n",
        "                hotel = data[0]\n",
        "                checks = [\n",
        "                    (\"name\" in hotel, \"Has 'name' field\"),\n",
        "                    (\"rating\" in hotel, \"Has 'rating' field\"),\n",
        "                    (\"area\" in hotel, \"Has 'area' field\"),\n",
        "                    (\"price_per_night\" in hotel, \"Has 'price_per_night' field (✅ CORRECT!)\"),\n",
        "                    (isinstance(hotel.get(\"price_per_night\"), (int, float)), \"price_per_night is numeric\"),\n",
        "                    (isinstance(hotel.get(\"rating\"), (int, float)), \"rating is numeric\"),\n",
        "                ]\n",
        "                for check, desc in checks:\n",
        "                    status = \"✅\" if check else \"❌\"\n",
        "                    print(f\"  {status} {desc}\")\n",
        "    else:\n",
        "        print(f\"⚠️  Unexpected response format: {type(data)}\")\n",
        "        print(f\"   Response: {str(data)[:200]}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Exception: {e}\")\n",
        "\n",
        "# Test 2: With filters\n",
        "print(\"\\n2️⃣  Test 2: With filters (max_price=200, min_rating=4.0)\")\n",
        "print(\"-\"*70)\n",
        "try:\n",
        "    # Access the underlying function (bypass @tool wrapper)\n",
        "    if hasattr(search_hotels_tool, '__wrapped__'):\n",
        "        actual_func = search_hotels_tool.__wrapped__\n",
        "    else:\n",
        "        actual_func = search_hotels_tool\n",
        "    \n",
        "    result = actual_func(\n",
        "        city=\"New York\",\n",
        "        checkin=\"2025-12-20\",\n",
        "        checkout=\"2025-12-21\",\n",
        "        max_price=200,\n",
        "        min_rating=4.0\n",
        "    )\n",
        "    data = json.loads(result)\n",
        "    \n",
        "    if \"error\" in data:\n",
        "        print(f\"⚠️  Error: {data['error']}\")\n",
        "    else:\n",
        "        print(f\"✅ Found {len(data)} hotels (filtered)\")\n",
        "        if len(data) > 0:\n",
        "            print(\"\\nFiltered results:\")\n",
        "            for i, hotel in enumerate(data, 1):\n",
        "                print(f\"  {i}. {hotel['name']} - ${hotel['price_per_night']}/night, Rating: {hotel['rating']}\")\n",
        "                # Verify filters\n",
        "                if hotel['price_per_night'] > 200:\n",
        "                    print(f\"     ⚠️  WARNING: Price exceeds max_price!\")\n",
        "                if hotel['rating'] < 4.0:\n",
        "                    print(f\"     ⚠️  WARNING: Rating below min_rating!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Exception: {e}\")\n",
        "\n",
        "# Test 3: Format validation\n",
        "print(\"\\n3️⃣  Test 3: Output format validation\")\n",
        "print(\"-\"*70)\n",
        "print(\"Expected format: List of dicts with 'name', 'rating', 'area', 'price_per_night'\")\n",
        "print(\"\\nTo test with real API:\")\n",
        "print(\"  1. Set SERPAPI_KEY: os.environ['SERPAPI_KEY'] = 'your_key'\")\n",
        "print(\"  2. Run: search_hotels_tool('Philadelphia', '2025-12-20', '2025-12-21')\")\n",
        "print(\"  3. Check that output has 'price_per_night' field (not 'raw_price_field')\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Test complete!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "8927b7b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Creating agent...\n",
            "✅ Agent created successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# SECTION 5: LLM & AGENT SETUP\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# Set your API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAOPrSe5SsfO8nUSYNtEt9fx7uxzKDeL3Q\"  # Replace with your actual key\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "# Create tools list\n",
        "tools = [\n",
        "    choose_city_tool,\n",
        "    search_flights_tool,\n",
        "    search_hotels_tool,\n",
        "    score_activities_tool,\n",
        "    fairness_tool,\n",
        "]\n",
        "\n",
        "# ✅ THE WORKING PROMPT (short and clear!)\n",
        "working_prompt = \"\"\"You are FairTripAgent. Plan a 2-day group trip.\n",
        "\n",
        "WORKFLOW:\n",
        "1. Call choose_city_tool with group_members JSON\n",
        "2. EXPLAIN what city was chosen and why (1-2 sentences)\n",
        "3. Call search_flights_tool for both trip windows\n",
        "4. EXPLAIN what flights you found and which is best (1-2 sentences)\n",
        "5. Call search_hotels_tool for that window\n",
        "6. EXPLAIN what hotels you found and which you'll choose (1-2 sentences)\n",
        "7. Call score_activities_tool for the destination\n",
        "8. EXPLAIN what activities you found - use summary if available (1-2 sentences)\n",
        "9. Build a 2-day itinerary (3 activities/day: morning, afternoon, evening)\n",
        "   - For EACH activity, include reasoning that references the user's \"notes\" field\n",
        "   - Explain WHY this activity would interest each user based on their preferences and notes\n",
        "   - Format: {\n",
        "       \"day1\": {\n",
        "         \"morning\": {\n",
        "           \"activity\": \"Activity name/description\",\n",
        "           \"reasoning\": \"Why this interests the group, referencing specific user notes (e.g., 'Alice loves walkable neighborhoods, so this urban walking tour fits her preference for speakeasies and walkable areas')\"\n",
        "         },\n",
        "         \"afternoon\": {...},\n",
        "         \"evening\": {...}\n",
        "       },\n",
        "       \"day2\": {...}\n",
        "     }\n",
        "   - IMPORTANT: The reasoning MUST reference specific user names and quote or paraphrase their \\\"notes\\\" field\n",
        "   - Example reasoning: \\\"This speakeasy tour appeals to Alice who 'loves walkable neighborhoods and speakeasies' (from her notes), and Emma who 'enjoys nightlife' and is 'happy to splurge a bit on nightlife' (from her notes). The urban walking aspect fits Alice's preference, while the evening timing matches Emma's nightlife interests.\\\"\n",
        "10. Call fairness_tool with costs\n",
        "11. EXPLAIN the fairness results (1-2 sentences)\n",
        "12. Return final JSON with: chosen_city, chosen_trip_window, chosen_flight, chosen_hotel, itinerary, fairness_summary, explanation\n",
        "\n",
        "CRITICAL: You MUST write a text explanation after EVERY tool call. Never skip this step. If a tool returns data, summarize it in 1-2 sentences before proceeding.\"\"\"\n",
        "\n",
        "# Create the agent\n",
        "print(\"✅ Creating agent...\")\n",
        "final_working_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt=working_prompt  # ✅ This is the key!\n",
        ")\n",
        "print(\"✅ Agent created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "8d7058d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📅 Most common window: 2025-12-20 to 2025-12-21\n",
            "   Preferred by 4 out of 5 members\n",
            "\n",
            "✈️  Origin cities:\n",
            "   Alice: ORD\n",
            "   Ben: JFK\n",
            "   Carla: LAX\n",
            "   Deepak: SFO\n",
            "   Emma: ATL\n",
            "\n",
            "================================================================================\n",
            "🚀 EXECUTING AGENT\n",
            "================================================================================\n",
            "\n",
            "\n",
            "📨 Total messages: 16\n",
            "\n",
            "1. [HumanMessage] Plan a trip for this group: {\"most_common_window\": {\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\", \"member_count\": 4, \"total_members\": 5}, \"trip_windows\": [{\"window_id\": \"W1\", \"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"}, {\"window_id\": \"W2\", \"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"}, {\"window_id\": \"W3\", \"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"}], \"group_members\": [{\"id\": \"u1\", \"name\": \"Alice\", \"origin_city\": \"ORD\", \"total_budget\": 9000, \"preference_weights\": {\"nightlife\": 4, \"adventure\": 1, \"shopping\": 1, \"food\": 5, \"urban\": 4}, \"notes\": \"Budget foodie, hates early mornings, loves walkable neighborhoods and speakeasies.\", \"preferred_windows\": [{\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"}, {\"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"}, {\"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"}]}, {\"id\": \"u2\", \"name\": \"Ben\", \"origin_city\": \"JFK\", \"total_budget\": 7000, \"preference_weights\": {\"nightlife\": 2, \"adventure\": 4, \"shopping\": 1, \"food\": 3, \"urban\": 3}, \"notes\": \"Loves outdoor activities and casual spots, not into heavy nightlife.\", \"preferred_windows\": [{\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"}, {\"trip_start\": \"2025-12-13\", \"trip_end\": \"2025-12-14\"}, {\"trip_start\": \"2026-01-10\", \"trip_end\": \"2026-01-11\"}]}, {\"id\": \"u3\", \"name\": \"Carla\", \"origin_city\": \"LAX\", \"total_budget\": 6500, \"preference_weights\": {\"nightlife\": 1, \"adventure\": 5, \"shopping\": 4, \"food\": 3, \"urban\": 1}, \"notes\": \"Enjoys shopping districts and museums, prefers quieter evenings.\", \"preferred_windows\": [{\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"}, {\"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"}, {\"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"}]}, {\"id\": \"u4\", \"name\": \"Deepak\", \"origin_city\": \"SFO\", \"total_budget\": 500, \"preference_weights\": {\"nightlife\": 1, \"adventure\": 5, \"shopping\": 2, \"food\": 3, \"urban\": 1}, \"notes\": \"On a tighter budget, okay with simple food, likes city walks and parks.\", \"preferred_windows\": [{\"trip_start\": \"2025-12-20\", \"trip_end\": \"2025-12-21\"}, {\"trip_start\": \"2025-12-13\", \"trip_end\": \"2025-12-14\"}, {\"trip_start\": \"2026-01-10\", \"trip_end\": \"2026-01-11\"}]}, {\"id\": \"u5\", \"name\": \"Emma\", \"origin_city\": \"ATL\", \"total_budget\": 1100, \"preference_weights\": {\"nightlife\": 1, \"adventure\": 5, \"shopping\": 1, \"food\": 2, \"urban\": 3}, \"notes\": \"Happy to splurge a bit on nightlife and good food.\", \"preferred_windows\": [{\"trip_start\": \"2025-12-27\", \"trip_end\": \"2025-12-28\"}, {\"trip_start\": \"2026-01-03\", \"trip_end\": \"2026-01-04\"}, {\"trip_start\": \"2026-01-10\", \"trip_end\": \"2026-01-11\"}]}]}\n",
            "2. [AIMessage] (empty)\n",
            "3. [ToolMessage] {\n",
            "  \"best_city\": \"Philadelphia\",\n",
            "  \"city_scores\": [\n",
            "    {\n",
            "      \"city\": \"Philadelphia\",\n",
            "      \"vibe_score\": 0.21207564596778883,\n",
            "      \"combined_score\": 0.21207564596778883,\n",
            "      \"avg_price_proxy\": 25.537190082644628,\n",
            "      \"cost_index\": 0.0,\n",
            "      \"typical_cost_level\": \"low\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.10485714285714286,\n",
            "        \"adventure\": 0.043333333333333335,\n",
            "        \"shopping\": 0.06373015873015873,\n",
            "        \"food\": 0.5778015873015873,\n",
            "        \"urban\": 0.21027777777777779\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"Tucson\",\n",
            "      \"vibe_score\": 0.20867468660968663,\n",
            "      \"combined_score\": 0.2050447416842492,\n",
            "      \"avg_price_proxy\": 25.646551724137932,\n",
            "      \"cost_index\": 0.02950530776535966,\n",
            "      \"typical_cost_level\": \"low\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.10698412698412699,\n",
            "        \"adventure\": 0.045,\n",
            "        \"shopping\": 0.08085714285714285,\n",
            "        \"food\": 0.5307698412698413,\n",
            "        \"urban\": 0.2363888888888889\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"Tampa\",\n",
            "      \"vibe_score\": 0.21445306461615987,\n",
            "      \"combined_score\": 0.1791691708201064,\n",
            "      \"avg_price_proxy\": 26.753731343283583,\n",
            "      \"cost_index\": 0.3282176804799384,\n",
            "      \"typical_cost_level\": \"low\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.13242063492063494,\n",
            "        \"adventure\": 0.04000000000000001,\n",
            "        \"shopping\": 0.039370370370370375,\n",
            "        \"food\": 0.6303201058201059,\n",
            "        \"urban\": 0.1578888888888889\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"Boise\",\n",
            "      \"vibe_score\": 0.21461404587476018,\n",
            "      \"combined_score\": 0.1617779270461513,\n",
            "      \"avg_price_proxy\": 27.554744525547445,\n",
            "      \"cost_index\": 0.5443276450350364,\n",
            "      \"typical_cost_level\": \"medium\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.17523015873015874,\n",
            "        \"adventure\": 0.03522222222222223,\n",
            "        \"shopping\": 0.014111111111111112,\n",
            "        \"food\": 0.6602619047619048,\n",
            "        \"urban\": 0.11517460317460318\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"city\": \"New Orleans\",\n",
            "      \"vibe_score\": 0.20438526425954995,\n",
            "      \"combined_score\": 0.1277407901751427,\n",
            "      \"avg_price_proxy\": 29.243697478991596,\n",
            "      \"cost_index\": 0.9999999997302043,\n",
            "      \"typical_cost_level\": \"high\",\n",
            "      \"n_places\": 150,\n",
            "      \"vibe_tags\": {\n",
            "        \"nightlife\": 0.13016666666666665,\n",
            "        \"adventure\": 0.021111111111111112,\n",
            "        \"shopping\": 0.04011904761904762,\n",
            "        \"food\": 0.49986507936507935,\n",
            "        \"urban\": 0.3087380952380952\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"explanation\": \"Philadelphia has the highest combined score (0.212) based on group preferences and cost.\"\n",
            "}\n",
            "4. [AIMessage] Philadelphia has been chosen as the best city for the group trip, primarily due to its high combined score that aligns well with the group's preferences and its low cost level.\n",
            "\n",
            "Now I will search for flights for each group member.\n",
            "5. [ToolMessage] [{\"price\": 219, \"airline\": \"American\", \"depart_time\": \"2025-12-20T2025-12-20 21:18\", \"arrive_time\": \"2025-12-21T2025-12-21 07:46\", \"legs\": 2}, {\"price\": 233, \"airline\": \"American\", \"depart_time\": \"2025-12-20T2025-12-20 20:53\", \"arrive_time\": \"2025-12-21T2025-12-21 07:30\", \"legs\": 2}, {\"price\": 283, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 12:39\", \"arrive_time\": \"2025-12-21T2025-12-21 00:41\", \"legs\": 2}]\n",
            "6. [ToolMessage] [{\"price\": 383, \"airline\": \"American\", \"depart_time\": \"2025-12-20T2025-12-20 21:30\", \"arrive_time\": \"2025-12-21T2025-12-21 07:30\", \"legs\": 2}, {\"price\": 513, \"airline\": \"JetBlue\", \"depart_time\": \"2025-12-20T2025-12-20 06:50\", \"arrive_time\": \"2025-12-21T2025-12-20 13:35\", \"legs\": 2}, {\"price\": 573, \"airline\": \"JetBlue\", \"depart_time\": \"2025-12-20T2025-12-20 08:41\", \"arrive_time\": \"2025-12-21T2025-12-20 13:35\", \"legs\": 2}]\n",
            "7. [ToolMessage] [{\"price\": 328, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 15:30\", \"arrive_time\": \"2025-12-21T2025-12-21 05:40\", \"legs\": 2}, {\"price\": 358, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 08:37\", \"arrive_time\": \"2025-12-21T2025-12-21 00:41\", \"legs\": 2}, {\"price\": 387, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 08:37\", \"arrive_time\": \"2025-12-21T2025-12-20 19:31\", \"legs\": 2}]\n",
            "8. [ToolMessage] [{\"price\": 409, \"airline\": \"Southwest\", \"depart_time\": \"2025-12-20T2025-12-20 18:40\", \"arrive_time\": \"2025-12-21T2025-12-21 09:10\", \"legs\": 3}, {\"price\": 680, \"airline\": \"Sun Country Airlines\", \"depart_time\": \"2025-12-20T2025-12-20 23:59\", \"arrive_time\": \"2025-12-21T2025-12-21 11:33\", \"legs\": 2}, {\"price\": 695, \"airline\": \"United\", \"depart_time\": \"2025-12-20T2025-12-20 22:35\", \"arrive_time\": \"2025-12-21T2025-12-21 09:55\", \"legs\": 2}]\n",
            "9. [ToolMessage] [{\"price\": 164, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 05:55\", \"arrive_time\": \"2025-12-21T2025-12-20 12:32\", \"legs\": 2}, {\"price\": 164, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 17:10\", \"arrive_time\": \"2025-12-21T2025-12-21 00:13\", \"legs\": 2}, {\"price\": 164, \"airline\": \"Frontier\", \"depart_time\": \"2025-12-20T2025-12-20 22:50\", \"arrive_time\": \"2025-12-21T2025-12-21 11:35\", \"legs\": 2}]\n",
            "10. [AIMessage] Philadelphia was chosen as the best city for the group due to its high combined score, balancing group preferences and cost-effectiveness.\n",
            "\n",
            "I found several flight options for each group member. For Alice (ORD), the best flight is with American for $219. For Ben (JFK), the best flight is with American for $383. For Carla (LAX), the best flight is with Frontier for $328. For Deepak (SFO), the best flight is with Southwest for $409. For Emma (ATL), the best flight is with Frontier for $164.\n",
            "11. [ToolMessage] [{\"price_per_night\": 120, \"name\": \"Central Inn\", \"rating\": 4.1, \"area\": \"Downtown\"}, {\"price_per_night\": 180, \"name\": \"Riverside Hotel\", \"rating\": 4.5, \"area\": \"Waterfront\"}, {\"price_per_night\": 90, \"name\": \"Budget Stay\", \"rating\": 3.4, \"area\": \"Suburbs\"}]\n",
            "12. [AIMessage] Philadelphia was chosen as the best city due to its high combined score, balancing group preferences for food and urban exploration with a low cost of living.\n",
            "\n",
            "For flights, I found the following cheapest options for the trip window of December 20-21, 2025: Alice from ORD for $219 (American), Ben from JFK for $383 (American), Carla from LAX for $328 (Frontier), Deepak from SFO for $409 (Southwest), and Emma from ATL for $164 (Frontier). These will be the chosen flights for each group member.\n",
            "\n",
            "Regarding hotels, I found three options in Philadelphia: Central Inn ($120/night, 4.1 rating), Riverside Hotel ($180/night, 4.5 rating), and Budget Stay ($90/night, 3.4 rating). I will choose the Central Inn for its good balance of price and rating, and its downtown location, which should be convenient for the group.\n",
            "13. [ToolMessage] {\"city\": \"Philadelphia\", \"summary\": {\"total_activities\": 50, \"score_range\": [3.0, 9.0], \"time_distribution\": {\"evening\": 25, \"afternoon\": 20, \"morning\": 5}}, \"activities\": [{\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"Pb5agnsD9EdCl6yuZp2jJA\", \"adjusted_enjoyment_score\": 9.0, \"recommended_time_of_day\": \"evening\", \"note\": \"High food score aligns with user's primary interest. Great for evening.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"c6r29yLfVhZaSyrtsNVLRQ\", \"adjusted_enjoyment_score\": 9.0, \"recommended_time_of_day\": \"evening\", \"note\": \"High food score aligns with user's primary interest. Great for evening.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"7BmboJEmyQ_DAgTCoCgpgg\", \"adjusted_enjoyment_score\": 9.0, \"recommended_time_of_day\": \"evening\", \"note\": \"High food score aligns with user's primary interest. Great for evening.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"fB_VJEJTIMyWv5hC9T-xwA\", \"adjusted_enjoyment_score\": 9.0, \"recommended_time_of_day\": \"evening\", \"note\": \"High food score aligns with user's primary interest. Great for evening.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"cLlBDZxYJ1dt1JgMuZnXew\", \"adjusted_enjoyment_score\": 8.5, \"recommended_time_of_day\": \"evening\", \"note\": \"Strong food and some nightlife interest. Good for an evening out.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"mmBwAe9q062vKWanRfoagQ\", \"adjusted_enjoyment_score\": 7.5, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Good urban and some food interest. User likes walkable neighborhoods.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"jvCNijeK9ZOf2Vb6pGNySg\", \"adjusted_enjoyment_score\": 6.0, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Some adventure and food, but not a strong match for user's preferences.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"uwF2zLAnZZ1SCwEF8QQKQA\", \"adjusted_enjoyment_score\": 6.0, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Good adventure and urban score. User likes walkable areas.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"pCmaISSyKum22MOtPOxL-w\", \"adjusted_enjoyment_score\": 5.0, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Sports event with food, but not a strong match for user's interests.\"}, {\"user_id\": \"u1\", \"city\": \"Philadelphia\", \"business_id\": \"eMjnw_7wp-CscyNh6Lu0ZA\", \"adjusted_enjoyment_score\": 4.0, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Urban focus, but not an activity for this user. Low enjoyment.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"uwF2zLAnZZ1SCwEF8QQKQA\", \"adjusted_enjoyment_score\": 9.0, \"recommended_time_of_day\": \"morning\", \"note\": \"High adventure and urban scores. Perfect for user's love of outdoor activities.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"Pb5agnsD9EdCl6yuZp2jJA\", \"adjusted_enjoyment_score\": 8.0, \"recommended_time_of_day\": \"evening\", \"note\": \"High food score aligns with user's interest. Casual dining is a good fit.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"c6r29yLfVhZaSyrtsNVLRQ\", \"adjusted_enjoyment_score\": 8.0, \"recommended_time_of_day\": \"evening\", \"note\": \"Strong food focus aligns with user's interests. Casual dining is a good fit.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"mmBwAe9q062vKWanRfoagQ\", \"adjusted_enjoyment_score\": 8.0, \"recommended_time_of_day\": \"morning\", \"note\": \"High urban and some food tags. Walking tours are casual and outdoor-friendly.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"7BmboJEmyQ_DAgTCoCgpgg\", \"adjusted_enjoyment_score\": 8.0, \"recommended_time_of_day\": \"evening\", \"note\": \"Excellent food score. User enjoys casual dining experiences.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"fB_VJEJTIMyWv5hC9T-xwA\", \"adjusted_enjoyment_score\": 8.0, \"recommended_time_of_day\": \"evening\", \"note\": \"High food score. User enjoys casual dining and food experiences.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"cLlBDZxYJ1dt1JgMuZnXew\", \"adjusted_enjoyment_score\": 7.5, \"recommended_time_of_day\": \"evening\", \"note\": \"Good food score and moderate urban tag. User likes casual spots.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"jvCNijeK9ZOf2Vb6pGNySg\", \"adjusted_enjoyment_score\": 7.0, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Adventure tag is present, and food is a bonus. User likes casual activities.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"pCmaISSyKum22MOtPOxL-w\", \"adjusted_enjoyment_score\": 6.5, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Baseball game offers food and urban experience, fitting user's casual preference.\"}, {\"user_id\": \"u2\", \"city\": \"Philadelphia\", \"business_id\": \"klGvxx2XmKkd-9mdRZoGVA\", \"adjusted_enjoyment_score\": 5.0, \"recommended_time_of_day\": \"afternoon\", \"note\": \"Urban experience, but not very engaging for someone who likes outdoor activities.\"}]}\n",
            "14. [AIMessage] Philadelphia was chosen as the best city for the group, scoring highest due to its balance of group preferences, particularly for food and urban experiences, and its low cost level.\n",
            "\n",
            "For flights, I found several options for each member for the trip window of December 20-21, 2025. The best flight for Alice from ORD is American for $219, for Ben from JFK is American for $383, for Carla from LAX is Frontier for $328, for Deepak from SFO is Southwest for $409, and for Emma from ATL is Frontier for $164. These are the most affordable options found for each individual.\n",
            "\n",
            "I found three hotel options in Philadelphia: Central Inn (Downtown, $120/night, 4.1 rating), Riverside Hotel (Waterfront, $180/night, 4.5 rating), and Budget Stay (Suburbs, $90/night, 3.4 rating). I will choose the Central Inn in Downtown for $120/night, as it offers a good balance of quality and location, being central and well-rated, which should appeal to the group's preferences for urban and walkable areas.\n",
            "\n",
            "The activity search returned a variety of options in Philadelphia, with enjoyment scores ranging from 3 to 9. There's a good distribution of activities suitable for afternoons and evenings, and some for mornings, allowing for a diverse itinerary.\n",
            "\n",
            "Here is a proposed 2-day itinerary for the group: ```json\n",
            "{\n",
            "  \"day1\": {\n",
            "    \"morning\": {\n",
            "      \"activity\": \"Morning City Walk & Historic Sites Tour\",\n",
            "      \"reasoning\": \"This activity appeals to Deepak who 'likes city walks and parks' and is 'on a tighter budget', as it's a cost-effective way to explore. Ben, who 'loves outdoor activities' and 'casual spots', will also enjoy the active and relaxed nature of a walking tour. Carla, who 'enjoys shopping districts and museums', will appreciate the historical and urban exploration.\"\n",
            "    },\n",
            "    \"afternoon\": {\n",
            "      \"activity\": \"Reading Terminal Market Food Exploration\",\n",
            "      \"reasoning\": \"This is perfect for Alice, a 'budget foodie' with a high food preference, and Emma, who is 'happy to splurge a bit on nightlife and good food'. Ben, who 'loves casual spots', will also enjoy the relaxed atmosphere and diverse food options. Deepak, who is 'okay with simple food', can find affordable and satisfying options here.\"\n",
            "    },\n",
            "    \"evening\": {\n",
            "      \"activity\": \"Speakeasy and Craft Cocktail Tour\",\n",
            "      \"reasoning\": \"This activity directly caters to Alice, who 'loves walkable neighborhoods and speakeasies' and has a high nightlife preference. Emma, who is 'happy to splurge a bit on nightlife', will also find this appealing. The urban and walkable aspect also aligns with Alice's preferences.\"\n",
            "    }\n",
            "  },\n",
            "  \"day2\": {\n",
            "    \"morning\": {\n",
            "      \"activity\": \"Philadelphia Museum of Art (Rocky Steps & Interior)\",\n",
            "      \"reasoning\": \"Carla 'enjoys shopping districts and museums', making this a great fit for her. Deepak, who 'likes city walks and parks', can enjoy the walk to the museum and the exterior, even if on a tighter budget for the interior. Ben, who 'loves outdoor activities', can appreciate the iconic 'Rocky Steps' and the surrounding park area.\"\n",
            "    },\n",
            "    \"afternoon\": {\n",
            "      \"activity\": \"Shopping in Rittenhouse Square\",\n",
            "      \"reasoning\": \"This activity is ideal for Carla, who 'enjoys shopping districts'. Alice, who 'loves walkable neighborhoods', will appreciate the urban environment. Emma, who is 'happy to splurge a bit on nightlife and good food', might also find some interesting shops or cafes to explore.\"\n",
            "    },\n",
            "    \"evening\": {\n",
            "      \"activity\": \"Dinner at a Highly-Rated Local Restaurant\",\n",
            "      \"reasoning\": \"This activity is a strong fit for Alice, a 'budget foodie' with a high food preference, and Emma, who is 'happy to splurge a bit on nightlife and good food'. Ben, who 'loves casual spots', can find a suitable restaurant, and Deepak, who is 'okay with simple food', can choose options within his budget.\"\n",
            "    }\n",
            "  }\n",
            "} ```\n",
            "15. [ToolMessage] {\"trip_fairness_score\": 60.0, \"mean_ratio\": 0.296, \"std_ratio\": 0.355, \"per_person\": [{\"name\": \"Alice\", \"trip_cost\": 399, \"budget\": 9000, \"affordability_ratio\": 0.044, \"affordability_label\": \"comfortable\"}, {\"name\": \"Ben\", \"trip_cost\": 513, \"budget\": 7000, \"affordability_ratio\": 0.073, \"affordability_label\": \"comfortable\"}, {\"name\": \"Carla\", \"trip_cost\": 458, \"budget\": 6500, \"affordability_ratio\": 0.07, \"affordability_label\": \"comfortable\"}, {\"name\": \"Deepak\", \"trip_cost\": 489, \"budget\": 500, \"affordability_ratio\": 0.978, \"affordability_label\": \"stretch\"}, {\"name\": \"Emma\", \"trip_cost\": 344, \"budget\": 1100, \"affordability_ratio\": 0.313, \"affordability_label\": \"comfortable\"}]}\n",
            "16. [AIMessage] Philadelphia was chosen as the best city for the group due to its highest combined score of 0.212, balancing group preferences and cost-effectiveness.\n",
            "\n",
            "For flights to Philadelphia on December 20-21, 2025, the best options are: Alice (ORD) on American for $219, Ben (JFK) on American for $383, Carla (LAX) on Frontier for $328, Deepak (SFO) on Southwest for $409, and Emma (ATL) on Frontier for $164. These flights offer the most economical choices for each group member.\n",
            "\n",
            "For accommodation in Philadelphia from December 20-21, 2025, the Central Inn in Downtown is the chosen hotel. It offers a good balance of price ($120/night) and a solid rating (4.1), with a convenient downtown location.\n",
            "\n",
            "The activity search for Philadelphia yielded a variety of options, with a strong emphasis on food and urban experiences, and some adventure and nightlife. The activities are distributed across morning, afternoon, and evening, with a score range from 3 to 9, indicating a good selection to match diverse group preferences.\n",
            "\n",
            "The trip has a fairness score of 60, with a mean affordability ratio of 0.296. Deepak's trip cost represents a \"stretch\" at 97.8% of his budget, while other members are comfortable within their budgets. ```json\n",
            "{\n",
            "  \"chosen_city\": \"Philadelphia\",\n",
            "  \"chosen_trip_window\": {\n",
            "    \"trip_start\": \"2025-12-20\",\n",
            "    \"trip_end\": \"2025-12-21\"\n",
            "  },\n",
            "  \"chosen_flight\": [\n",
            "    {\n",
            "      \"name\": \"Alice\",\n",
            "      \"airline\": \"American\",\n",
            "      \"price\": 219,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 21:18\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 07:46\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Ben\",\n",
            "      \"airline\": \"American\",\n",
            "      \"price\": 383,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 21:30\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 07:30\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Carla\",\n",
            "      \"airline\": \"Frontier\",\n",
            "      \"price\": 328,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 15:30\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 05:40\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Deepak\",\n",
            "      \"airline\": \"Southwest\",\n",
            "      \"price\": 409,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 18:40\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 09:10\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Emma\",\n",
            "      \"airline\": \"Frontier\",\n",
            "      \"price\": 164,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 05:55\",\n",
            "      \"arrive_time\": \"2025-12-20T2025-12-20 12:32\"\n",
            "    }\n",
            "  ],\n",
            "  \"chosen_hotel\": {\n",
            "    \"name\": \"Central Inn\",\n",
            "    \"area\": \"Downtown\",\n",
            "    \"price_per_night\": 120,\n",
            "    \"rating\": 4.1\n",
            "  },\n",
            "  \"itinerary\": {\n",
            "    \"day1\": {\n",
            "      \"morning\": {\n",
            "        \"activity\": \"Historic Philadelphia Walking Tour\",\n",
            "        \"reasoning\": \"This urban walking tour appeals to Alice who 'loves walkable neighborhoods' (from her notes), Ben who 'loves outdoor activities and casual spots' (from his notes), and Deepak who 'likes city walks and parks' (from his notes). It's a great way to explore the city's urban environment at a relaxed pace, accommodating Alice's preference for not-too-early mornings.\"\n",
            "      },\n",
            "      \"afternoon\": {\n",
            "        \"activity\": \"Philadelphia Museum of Art\",\n",
            "        \"reasoning\": \"This activity caters to Carla who 'enjoys shopping districts and museums' (from her notes), offering a cultural experience. It also provides an urban experience for Alice and Emma, and a more relaxed indoor option for the group.\"\n",
            "      },\n",
            "      \"evening\": {\n",
            "        \"activity\": \"Speakeasy and Food Experience in a Historic Neighborhood\",\n",
            "        \"reasoning\": \"This activity is perfect for Alice who 'loves walkable neighborhoods and speakeasies' (from her notes) and is a 'budget foodie'. Emma, who is 'happy to splurge a bit on nightlife and good food' (from her notes), will also enjoy this. The combination of a speakeasy and food aligns with their preferences for nightlife and culinary experiences in a vibrant, walkable area.\"\n",
            "      }\n",
            "    },\n",
            "    \"day2\": {\n",
            "      \"morning\": {\n",
            "        \"activity\": \"Fairmount Park Exploration and Outdoor Activities\",\n",
            "        \"reasoning\": \"This outdoor adventure in Fairmount Park is ideal for Ben who 'loves outdoor activities' (from his notes), Deepak who 'likes city walks and parks' (from his notes), and Emma who has a high 'adventure' preference. It offers a chance to enjoy nature and active exploration within an urban setting.\"\n",
            "      },\n",
            "      \"afternoon\": {\n",
            "        \"activity\": \"Reading Terminal Market Food Exploration\",\n",
            "        \"reasoning\": \"This activity is a fantastic choice for Alice, a 'Budget foodie' (from her notes), and Deepak who is 'okay with simple food' (from his notes) and on a 'tighter budget'. Ben, who enjoys 'casual spots' and food, and Emma, who is 'happy to splurge a bit on... good food' (from her notes), will also find a variety of options to enjoy in this vibrant market setting.\"\n",
            "      },\n",
            "      \"evening\": {\n",
            "        \"activity\": \"Group Dinner at a Highly-Rated Local Restaurant\",\n",
            "        \"reasoning\": \"This farewell dinner caters to Alice, a 'Budget foodie' (from her notes), and Emma, who is 'happy to splurge a bit on nightlife and good food' (from her notes). Ben, who enjoys 'casual spots' and food, and Carla, who prefers 'quieter evenings' (from her notes), can also find suitable options for a pleasant dining experience, ensuring a good culinary end to the trip for everyone.\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"fairness_summary\": {\n",
            "    \"trip_fairness_score\": 60,\n",
            "    \"mean_ratio\": 0.296,\n",
            "    \"std_ratio\": 0.355,\n",
            "    \"per_person\": [\n",
            "      {\n",
            "        \"name\": \"Alice\",\n",
            "        \"budget\": 9000,\n",
            "        \"trip_cost\": 399,\n",
            "        \"affordability_ratio\": 0.044,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Ben\",\n",
            "        \"budget\": 7000,\n",
            "        \"trip_cost\": 513,\n",
            "        \"affordability_ratio\": 0.073,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Carla\",\n",
            "        \"budget\": 6500,\n",
            "        \"trip_cost\": 458,\n",
            "        \"affordability_ratio\": 0.07,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Deepak\",\n",
            "        \"budget\": 500,\n",
            "        \"trip_cost\": 489,\n",
            "        \"affordability_ratio\": 0.978,\n",
            "        \"affordability_label\": \"stretch\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Emma\",\n",
            "        \"budget\": 1100,\n",
            "        \"trip_cost\": 344,\n",
            "        \"affordability_ratio\": 0.313,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"explanation\": \"The trip to Philadelphia is planned for December 20-21, 2025. Flights have been selected for each member, with the Central Inn chosen for accommodation. The itinerary balances various group preferences, including food, urban exploration, museums, and outdoor activities. The fairness analysis indicates that while most members are comfortable within their budgets, Deepak's trip cost represents a significant portion of his total budget.\"\n",
            "}\n",
            "```\n",
            "\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "📝 FINAL RESPONSE:\n",
            "================================================================================\n",
            "Philadelphia was chosen as the best city for the group due to its highest combined score of 0.212, balancing group preferences and cost-effectiveness.\n",
            "\n",
            "For flights to Philadelphia on December 20-21, 2025, the best options are: Alice (ORD) on American for $219, Ben (JFK) on American for $383, Carla (LAX) on Frontier for $328, Deepak (SFO) on Southwest for $409, and Emma (ATL) on Frontier for $164. These flights offer the most economical choices for each group member.\n",
            "\n",
            "For accommodation in Philadelphia from December 20-21, 2025, the Central Inn in Downtown is the chosen hotel. It offers a good balance of price ($120/night) and a solid rating (4.1), with a convenient downtown location.\n",
            "\n",
            "The activity search for Philadelphia yielded a variety of options, with a strong emphasis on food and urban experiences, and some adventure and nightlife. The activities are distributed across morning, afternoon, and evening, with a score range from 3 to 9, indicating a good selection to match diverse group preferences.\n",
            "\n",
            "The trip has a fairness score of 60, with a mean affordability ratio of 0.296. Deepak's trip cost represents a \"stretch\" at 97.8% of his budget, while other members are comfortable within their budgets. ```json\n",
            "{\n",
            "  \"chosen_city\": \"Philadelphia\",\n",
            "  \"chosen_trip_window\": {\n",
            "    \"trip_start\": \"2025-12-20\",\n",
            "    \"trip_end\": \"2025-12-21\"\n",
            "  },\n",
            "  \"chosen_flight\": [\n",
            "    {\n",
            "      \"name\": \"Alice\",\n",
            "      \"airline\": \"American\",\n",
            "      \"price\": 219,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 21:18\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 07:46\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Ben\",\n",
            "      \"airline\": \"American\",\n",
            "      \"price\": 383,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 21:30\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 07:30\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Carla\",\n",
            "      \"airline\": \"Frontier\",\n",
            "      \"price\": 328,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 15:30\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 05:40\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Deepak\",\n",
            "      \"airline\": \"Southwest\",\n",
            "      \"price\": 409,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 18:40\",\n",
            "      \"arrive_time\": \"2025-12-21T2025-12-21 09:10\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Emma\",\n",
            "      \"airline\": \"Frontier\",\n",
            "      \"price\": 164,\n",
            "      \"depart_time\": \"2025-12-20T2025-12-20 05:55\",\n",
            "      \"arrive_time\": \"2025-12-20T2025-12-20 12:32\"\n",
            "    }\n",
            "  ],\n",
            "  \"chosen_hotel\": {\n",
            "    \"name\": \"Central Inn\",\n",
            "    \"area\": \"Downtown\",\n",
            "    \"price_per_night\": 120,\n",
            "    \"rating\": 4.1\n",
            "  },\n",
            "  \"itinerary\": {\n",
            "    \"day1\": {\n",
            "      \"morning\": {\n",
            "        \"activity\": \"Historic Philadelphia Walking Tour\",\n",
            "        \"reasoning\": \"This urban walking tour appeals to Alice who 'loves walkable neighborhoods' (from her notes), Ben who 'loves outdoor activities and casual spots' (from his notes), and Deepak who 'likes city walks and parks' (from his notes). It's a great way to explore the city's urban environment at a relaxed pace, accommodating Alice's preference for not-too-early mornings.\"\n",
            "      },\n",
            "      \"afternoon\": {\n",
            "        \"activity\": \"Philadelphia Museum of Art\",\n",
            "        \"reasoning\": \"This activity caters to Carla who 'enjoys shopping districts and museums' (from her notes), offering a cultural experience. It also provides an urban experience for Alice and Emma, and a more relaxed indoor option for the group.\"\n",
            "      },\n",
            "      \"evening\": {\n",
            "        \"activity\": \"Speakeasy and Food Experience in a Historic Neighborhood\",\n",
            "        \"reasoning\": \"This activity is perfect for Alice who 'loves walkable neighborhoods and speakeasies' (from her notes) and is a 'budget foodie'. Emma, who is 'happy to splurge a bit on nightlife and good food' (from her notes), will also enjoy this. The combination of a speakeasy and food aligns with their preferences for nightlife and culinary experiences in a vibrant, walkable area.\"\n",
            "      }\n",
            "    },\n",
            "    \"day2\": {\n",
            "      \"morning\": {\n",
            "        \"activity\": \"Fairmount Park Exploration and Outdoor Activities\",\n",
            "        \"reasoning\": \"This outdoor adventure in Fairmount Park is ideal for Ben who 'loves outdoor activities' (from his notes), Deepak who 'likes city walks and parks' (from his notes), and Emma who has a high 'adventure' preference. It offers a chance to enjoy nature and active exploration within an urban setting.\"\n",
            "      },\n",
            "      \"afternoon\": {\n",
            "        \"activity\": \"Reading Terminal Market Food Exploration\",\n",
            "        \"reasoning\": \"This activity is a fantastic choice for Alice, a 'Budget foodie' (from her notes), and Deepak who is 'okay with simple food' (from his notes) and on a 'tighter budget'. Ben, who enjoys 'casual spots' and food, and Emma, who is 'happy to splurge a bit on... good food' (from her notes), will also find a variety of options to enjoy in this vibrant market setting.\"\n",
            "      },\n",
            "      \"evening\": {\n",
            "        \"activity\": \"Group Dinner at a Highly-Rated Local Restaurant\",\n",
            "        \"reasoning\": \"This farewell dinner caters to Alice, a 'Budget foodie' (from her notes), and Emma, who is 'happy to splurge a bit on nightlife and good food' (from her notes). Ben, who enjoys 'casual spots' and food, and Carla, who prefers 'quieter evenings' (from her notes), can also find suitable options for a pleasant dining experience, ensuring a good culinary end to the trip for everyone.\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"fairness_summary\": {\n",
            "    \"trip_fairness_score\": 60,\n",
            "    \"mean_ratio\": 0.296,\n",
            "    \"std_ratio\": 0.355,\n",
            "    \"per_person\": [\n",
            "      {\n",
            "        \"name\": \"Alice\",\n",
            "        \"budget\": 9000,\n",
            "        \"trip_cost\": 399,\n",
            "        \"affordability_ratio\": 0.044,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Ben\",\n",
            "        \"budget\": 7000,\n",
            "        \"trip_cost\": 513,\n",
            "        \"affordability_ratio\": 0.073,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Carla\",\n",
            "        \"budget\": 6500,\n",
            "        \"trip_cost\": 458,\n",
            "        \"affordability_ratio\": 0.07,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Deepak\",\n",
            "        \"budget\": 500,\n",
            "        \"trip_cost\": 489,\n",
            "        \"affordability_ratio\": 0.978,\n",
            "        \"affordability_label\": \"stretch\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Emma\",\n",
            "        \"budget\": 1100,\n",
            "        \"trip_cost\": 344,\n",
            "        \"affordability_ratio\": 0.313,\n",
            "        \"affordability_label\": \"comfortable\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"explanation\": \"The trip to Philadelphia is planned for December 20-21, 2025. Flights have been selected for each member, with the Central Inn chosen for accommodation. The itinerary balances various group preferences, including food, urban exploration, museums, and outdoor activities. The fairness analysis indicates that while most members are comfortable within their budgets, Deepak's trip cost represents a significant portion of his total budget.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# SECTION 6: EXECUTE AGENT\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def extract_message_content(msg):\n",
        "    \"\"\"Safely extract content from a message, handling both string and list formats.\"\"\"\n",
        "    if not msg.content:\n",
        "        return \"\"\n",
        "    \n",
        "    if isinstance(msg.content, list):\n",
        "        # Join list items into a single string\n",
        "        return \" \".join(str(item) for item in msg.content)\n",
        "    else:\n",
        "        return str(msg.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test request\n",
        "    # Find the most common window from all members' preferences\n",
        "    most_common_window = find_most_common_window(group_members)\n",
        "    \n",
        "    # Build trip_windows list from all unique preferred windows\n",
        "    all_windows = []\n",
        "    seen_windows = set()\n",
        "    for member in group_members:\n",
        "        for window in member.get(\"preferred_windows\", []):\n",
        "            window_key = (window.get(\"trip_start\"), window.get(\"trip_end\"))\n",
        "            if window_key not in seen_windows and window_key[0] and window_key[1]:\n",
        "                all_windows.append({\n",
        "                    \"window_id\": f\"W{len(all_windows) + 1}\",\n",
        "                    \"trip_start\": window[\"trip_start\"],\n",
        "                    \"trip_end\": window[\"trip_end\"]\n",
        "                })\n",
        "                seen_windows.add(window_key)\n",
        "    \n",
        "    # Create test request with most common window highlighted\n",
        "    test_request = {\n",
        "        \"most_common_window\": most_common_window,  # The window most members prefer\n",
        "        \"trip_windows\": all_windows[:3],  # Top 3 unique windows\n",
        "        \"group_members\": group_members  # All members with their own origin cities\n",
        "    }\n",
        "    \n",
        "    print(f\"📅 Most common window: {most_common_window['trip_start']} to {most_common_window['trip_end']}\")\n",
        "    print(f\"   Preferred by {most_common_window['member_count']} out of {most_common_window['total_members']} members\")\n",
        "    print(f\"\\n✈️  Origin cities:\")\n",
        "    for member in group_members:\n",
        "        print(f\"   {member['name']}: {member['origin_city']}\")\n",
        "\n",
        "    test_msg = f\"Plan a trip for this group: {json.dumps(test_request)}\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🚀 EXECUTING AGENT\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Run the agent\n",
        "    result = final_working_agent.invoke({\"messages\": [(\"user\", test_msg)]})\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n📨 Total messages: {len(result['messages'])}\\n\")\n",
        "    \n",
        "    for i, msg in enumerate(result['messages']):\n",
        "        print(f\"{i+1}. [{type(msg).__name__}] \", end=\"\")\n",
        "        \n",
        "        # Safely extract content (handles both string and list)\n",
        "        content_str = extract_message_content(msg)\n",
        "        \n",
        "        if content_str:\n",
        "            # Print full message content (display only, doesn't affect API usage)\n",
        "            print(content_str)\n",
        "        else:\n",
        "            print(\"(empty)\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📝 FINAL RESPONSE:\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Safely extract final content (handles both string and list)\n",
        "    final_content_str = extract_message_content(result['messages'][-1])\n",
        "    print(final_content_str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fcf8afc",
      "metadata": {
        "id": "1fcf8afc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0874937",
      "metadata": {
        "id": "d0874937"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
